{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import rasterio \n",
    "import rasterio.plot\n",
    "from rasterio.mask import mask\n",
    "from glob import glob\n",
    "import time\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history = pd.read_excel(r'data_raw/ML_BDR_20201019.xlsx', \n",
    "                                    names=['county_acronym', 'county_nr', 'fdist_nr', 'fdist_id','year', \n",
    "                                           'timeframe', 'forest_ownership', 'infested_wood', 'disposed_wood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LK = county_acronym\n",
    "# LK-Nr = county_nr\n",
    "# LK-Rev = fdist_nr\n",
    "# fdist_id = fdist_id\n",
    "# Jahr = year\n",
    "# ZR = timeframe\n",
    "# Eigentumsgruppe = forest_ownership\n",
    "# Zugang = infested_wood\n",
    "# Abgang = disposed_wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_acronym</th>\n",
       "      <th>county_nr</th>\n",
       "      <th>fdist_nr</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>forest_ownership</th>\n",
       "      <th>infested_wood</th>\n",
       "      <th>disposed_wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>06 Juni</td>\n",
       "      <td>SW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>08 August</td>\n",
       "      <td>SW</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2008</td>\n",
       "      <td>04 April</td>\n",
       "      <td>SW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2008</td>\n",
       "      <td>06 Juni</td>\n",
       "      <td>SW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  county_acronym  county_nr  fdist_nr  fdist_id  year            timeframe  \\\n",
       "0             BZ         25         1      2501  2007              06 Juni   \n",
       "1             BZ         25         1      2501  2007            08 August   \n",
       "2             BZ         25         1      2501  2007  10 Oktober-Dezember   \n",
       "3             BZ         25         1      2501  2008             04 April   \n",
       "4             BZ         25         1      2501  2008              06 Juni   \n",
       "\n",
       "  forest_ownership  infested_wood  disposed_wood  \n",
       "0               SW            5.0            0.0  \n",
       "1               SW           12.0           12.0  \n",
       "2               SW            2.0            0.0  \n",
       "3               SW            1.0            0.0  \n",
       "4               SW            2.0            0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infestation_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forestry Districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fdist_id column contains a unique identifier for the forstry districts. The first two digits indicate the county (Landkreis) and the last two digits indicate the number of the district in this county. \n",
    "\n",
    "In some forestry districts the district number (last two digits) begins with a leading 9 instead of a leading 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 1101,\n",
       "       1201, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2191, 2192, 2193,\n",
       "       2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2601, 2602,\n",
       "       2603, 2604, 2605, 2606, 2691, 2901, 2902, 2701, 2702, 2703, 2704,\n",
       "       2791, 2792, 2793, 2801, 2802, 2803, 2804, 2805, 3001, 3002, 3003,\n",
       "       2301, 2302, 2303, 2304, 2305, 2306, 2401, 2402], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all forestry district numbers\n",
    "infestation_history['fdist_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the observation timeframe, some of the districts (*Erzgebirgskreis* and *Meißen*) underwent a restructuring process. A leading 9 instead of a leading 0 signifies that the border of the district was different than it is today.  We can see when these changes happened with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_acronym</th>\n",
       "      <th>county_nr</th>\n",
       "      <th>fdist_nr</th>\n",
       "      <th>year</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>forest_ownership</th>\n",
       "      <th>infested_wood</th>\n",
       "      <th>disposed_wood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdist_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>4430.82</td>\n",
       "      <td>4701.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>92</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>2029.06</td>\n",
       "      <td>2185.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>93</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>231.00</td>\n",
       "      <td>238.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>94</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>445.00</td>\n",
       "      <td>460.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>95</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>1238.38</td>\n",
       "      <td>1219.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>1140.88</td>\n",
       "      <td>1157.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>97</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>1035.00</td>\n",
       "      <td>1268.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>ERZ</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>2014</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>175.75</td>\n",
       "      <td>164.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>GR</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>2020</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>NSW</td>\n",
       "      <td>18000.00</td>\n",
       "      <td>15200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>MEI</td>\n",
       "      <td>27</td>\n",
       "      <td>91</td>\n",
       "      <td>2013</td>\n",
       "      <td>01 Januar-März</td>\n",
       "      <td>NSW</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>MEI</td>\n",
       "      <td>27</td>\n",
       "      <td>92</td>\n",
       "      <td>2013</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>271.25</td>\n",
       "      <td>209.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>MEI</td>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "      <td>2013</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>70.00</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         county_acronym  county_nr  fdist_nr  year            timeframe  \\\n",
       "fdist_id                                                                  \n",
       "2191                ERZ         21        91  2014  10 Oktober-Dezember   \n",
       "2192                ERZ         21        92  2014  10 Oktober-Dezember   \n",
       "2193                ERZ         21        93  2014  10 Oktober-Dezember   \n",
       "2194                ERZ         21        94  2014  10 Oktober-Dezember   \n",
       "2195                ERZ         21        95  2014  10 Oktober-Dezember   \n",
       "2196                ERZ         21        96  2014  10 Oktober-Dezember   \n",
       "2197                ERZ         21        97  2014  10 Oktober-Dezember   \n",
       "2198                ERZ         21        98  2014  10 Oktober-Dezember   \n",
       "2691                 GR         26        91  2020  10 Oktober-Dezember   \n",
       "2791                MEI         27        91  2013       01 Januar-März   \n",
       "2792                MEI         27        92  2013  10 Oktober-Dezember   \n",
       "2793                MEI         27        93  2013  10 Oktober-Dezember   \n",
       "\n",
       "         forest_ownership  infested_wood  disposed_wood  \n",
       "fdist_id                                                 \n",
       "2191                   SW        4430.82        4701.61  \n",
       "2192                   SW        2029.06        2185.31  \n",
       "2193                   SW         231.00         238.00  \n",
       "2194                   SW         445.00         460.00  \n",
       "2195                   SW        1238.38        1219.88  \n",
       "2196                   SW        1140.88        1157.92  \n",
       "2197                   SW        1035.00        1268.00  \n",
       "2198                   SW         175.75         164.35  \n",
       "2691                  NSW       18000.00       15200.00  \n",
       "2791                  NSW          15.00          15.00  \n",
       "2792                   SW         271.25         209.75  \n",
       "2793                   SW          70.00          72.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infestation_history[infestation_history['fdist_nr'] >= 90].groupby('fdist_id').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to do this grouping by 'fdist_nr' because the two parts of 'fdist_id' also appear in the 'county_nr' and 'fdist_nr' columns seperately. This also means that they are redundant. We check if the information the three columns contain are really the same for every observation and then drop 'county_nr' and 'fdist_nr':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first column as a string\n",
    "county_nr = infestation_history['county_nr'].astype(str) \n",
    "# second column as a string with leading zero\n",
    "fdist_nr = infestation_history['fdist_nr'].astype(str).map(lambda x: x.zfill(2)) \n",
    "\n",
    "# concatenate these strings and check if they are identical to the 'fdist_id' column at every observation\n",
    "(county_nr + fdist_nr == infestation_history['fdist_id'].astype(str)).all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'county_nr' and 'fdist_nr' columns because the information is also found in 'fdist_id'\n",
    "infestation_history.drop(['county_nr', 'fdist_nr', 'county_acronym'], axis=1, inplace=True)\n",
    "\n",
    "# TODO: remove the following comments or keep 'LK'\n",
    "# the 'LK' column is also redundant as it contains a string that matches its 'fdist_nr' column\n",
    "# since we can use it in the EDA more intuitively than just the different 'fdist_id' numbers we will keep it for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we continue examining the cases with leading 9s. The *Stadtwald Zittau* (fdist_id 2691) is a special case among those special cases. According to Sachsenforst the correct procedure is to just add the corresponding observations to the forestry district *Zittau* (fdist_id 2601)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in column 'fdist_id' change all occurrences of 2691 to 2601\n",
    "infestation_history['fdist_id'] = infestation_history['fdist_id'].replace(2691, 2601)\n",
    "\n",
    "# aggregate the values by summing them together for the 'infested_wood' and 'disposed_wood' columns if every other column value is the same\n",
    "infestation_history['infested_wood'] = infestation_history.groupby(['fdist_id', 'year', 'timeframe', 'forest_ownership'])['infested_wood'].transform('sum')\n",
    "\n",
    "infestation_history['disposed_wood'] = infestation_history.groupby(['fdist_id', 'year', 'timeframe', 'forest_ownership'])['disposed_wood'].transform('sum')\n",
    "\n",
    "# Now drop the duplicated rows that were just created\n",
    "infestation_history.drop_duplicates(inplace=True)\n",
    "\n",
    "# reset the index\n",
    "infestation_history.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8008, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infestation_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining forestry districts we need to distinguish between the old borders and the new ones. Sachsenforst supplied us with two shape files, one with all current district borders and one with only borders of old districts that were different than they are now. We only have to change the 'fdist_id' numbers for the abolished districts so they match the format with the leading 9s and then merge both geodataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mittelsachsen</td>\n",
       "      <td>Reinsberg</td>\n",
       "      <td>2203</td>\n",
       "      <td>1597.32</td>\n",
       "      <td>3274.630917</td>\n",
       "      <td>2706.18</td>\n",
       "      <td>2133.910411</td>\n",
       "      <td>POLYGON ((386902.476 5656907.025, 386910.595 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mittelsachsen</td>\n",
       "      <td>Geringswalde</td>\n",
       "      <td>2201</td>\n",
       "      <td>841.61</td>\n",
       "      <td>3508.605810</td>\n",
       "      <td>196.15</td>\n",
       "      <td>1453.972847</td>\n",
       "      <td>POLYGON ((332902.962 5650328.573, 332905.989 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Leipziger Land</td>\n",
       "      <td>2902</td>\n",
       "      <td>401.71</td>\n",
       "      <td>8199.853850</td>\n",
       "      <td>615.51</td>\n",
       "      <td>5314.476829</td>\n",
       "      <td>POLYGON ((332897.160 5650325.466, 332893.592 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_name      fdist_name fdist_id  area_nse    area_nsne  area_se  \\\n",
       "0  Mittelsachsen       Reinsberg     2203   1597.32  3274.630917  2706.18   \n",
       "1  Mittelsachsen    Geringswalde     2201    841.61  3508.605810   196.15   \n",
       "2        Leipzig  Leipziger Land     2902    401.71  8199.853850   615.51   \n",
       "\n",
       "      area_sne                                           geometry  \n",
       "0  2133.910411  POLYGON ((386902.476 5656907.025, 386910.595 5...  \n",
       "1  1453.972847  POLYGON ((332902.962 5650328.573, 332905.989 5...  \n",
       "2  5314.476829  POLYGON ((332897.160 5650325.466, 332893.592 5...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the first shape file as a geopandas geodataframe\n",
    "districts_new = gpd.read_file(r'data_raw/shape/ufb_rev_wald_teil.shp', \n",
    "                              encoding='utf-8')\n",
    "\n",
    "# gpd.read_file has no 'names' argument, so we still need to change the column names after reading\n",
    "districts_new.columns=['county_name', 'fdist_name', 'fdist_id', 'area_nse', \n",
    "                                     'area_nsne', 'area_se', 'area_sne', 'geometry']\n",
    "\n",
    "districts_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KREIS_NAME = county_name\n",
    "# REVUFB_NM = fdist_name\n",
    "# REVUFBADR = fdist_id\n",
    "# NSW_FI = area_nse\n",
    "# NSW_SONST = area_nsne\n",
    "# SW_FI = area_se\n",
    "# SW_SONST = area_sne\n",
    "# geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>Nord</td>\n",
       "      <td>2703</td>\n",
       "      <td>143.31</td>\n",
       "      <td>5780.407594</td>\n",
       "      <td>1.09</td>\n",
       "      <td>768.093453</td>\n",
       "      <td>POLYGON ((418952.942 5692288.782, 418909.147 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>West</td>\n",
       "      <td>2701</td>\n",
       "      <td>22.80</td>\n",
       "      <td>4255.041515</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3650.063576</td>\n",
       "      <td>POLYGON ((389635.997 5699901.234, 389648.747 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>Süd</td>\n",
       "      <td>2702</td>\n",
       "      <td>411.13</td>\n",
       "      <td>4543.837549</td>\n",
       "      <td>381.83</td>\n",
       "      <td>1975.417673</td>\n",
       "      <td>POLYGON ((378695.051 5678837.912, 378676.082 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  county_name fdist_name fdist_id  area_nse    area_nsne  area_se  \\\n",
       "0      Meißen       Nord     2703    143.31  5780.407594     1.09   \n",
       "1      Meißen       West     2701     22.80  4255.041515     3.93   \n",
       "2      Meißen        Süd     2702    411.13  4543.837549   381.83   \n",
       "\n",
       "      area_sne                                           geometry  \n",
       "0   768.093453  POLYGON ((418952.942 5692288.782, 418909.147 5...  \n",
       "1  3650.063576  POLYGON ((389635.997 5699901.234, 389648.747 5...  \n",
       "2  1975.417673  POLYGON ((378695.051 5678837.912, 378676.082 5...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the second shape file as a geopandas geodataframe\n",
    "districts_old = gpd.read_file(r'data_raw/shape/ufb_rev_vorUmstrukturierungen.shp', \n",
    "                              encoding='utf-8')\n",
    "\n",
    "# gpd.read_file has no 'names' argument, so we still need to change the column names after reading\n",
    "districts_old.columns=['county_name', 'fdist_name', 'fdist_id', 'area_nse', \n",
    "                                     'area_nsne', 'area_se', 'area_sne', 'geometry']\n",
    "\n",
    "districts_old.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 90 to every 'fdist_id' in the districts_old dataframe to get the leading 9 notation for abolished forestry districts\n",
    "districts_old['fdist_id'] = districts_old['fdist_id'].astype(int) + 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change 'fdist_id' of districts_new to type int\n",
    "districts_new['fdist_id'] = districts_new['fdist_id'].astype(int)\n",
    "\n",
    "# merge the geodataframes\n",
    "districts = pd.merge(districts_new, districts_old, how ='outer') \n",
    "\n",
    "# shape should be 64x8 now\n",
    "districts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old and new district borders are now present as well as correctly labeled in both the geodata and the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area for Kreisfreie Stadt Leipzig is 297.8 km^2, should be 297.8 km^2\n"
     ]
    }
   ],
   "source": [
    "# calculate area of the forestry district polygons in square kilometeres\n",
    "# to get the correct area, we use an equal area projection (in this case cea) \n",
    "districts['area_fdist'] = districts.to_crs({'proj':'cea'})['geometry'].area/1000000\n",
    "\n",
    "# we briefly evaluate the results by checking the area for the town of Leipzig \n",
    "# area should be 297.8 km^2 according to wikipedia\n",
    "kfs_leipzig_area = districts[districts['county_name'] == 'Kreisfreie Stadt Leipzig']['area_fdist'].sum()\n",
    "print(f'Area for Kreisfreie Stadt Leipzig is {round(kfs_leipzig_area, 1)} km^2, should be 297.8 km^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endangered forest density\n",
    "# TODO: Kommentieren\n",
    "districts['endangered_forest_density'] = (districts['area_nse'] + districts['area_se'])*100/districts['area_fdist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for coordinates of centroid for every district\n",
    "# maybe useful as features instead of dummy for every district\n",
    "districts['centroid_xcoord'] = districts['geometry'].map(lambda x: x.centroid.coords[0][0])\n",
    "districts['centroid_ycoord'] = districts['geometry'].map(lambda x: x.centroid.coords[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make one more modification and the change some forestry district names slightly to make them unambiguous. Currently, Meißen as well as Zwickau have their districts labeled as *Nord* (north), *Süd* (south) etc. Since we also have the 'county_name' column to distinguish them, this is not a dealbreaker. In case we ever just want to use the district names however, we should be able do differentiate between them. Thus we add the first county name letter to the name ('M Nord'), ('Z Nord') and so on for those forestry districts only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.loc[districts['county_name'] == 'Zwickau', 'fdist_name'] = districts.loc[districts['county_name'] == 'Zwickau', 'fdist_name'].map(lambda x: 'Z '+x)\n",
    "districts.loc[districts['county_name'] == 'Meißen', 'fdist_name'] = districts.loc[districts['county_name'] == 'Meißen', 'fdist_name'].map(lambda x: 'M '+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area_fdist</th>\n",
       "      <th>endangered_forest_density</th>\n",
       "      <th>centroid_xcoord</th>\n",
       "      <th>centroid_ycoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Nord</td>\n",
       "      <td>2701</td>\n",
       "      <td>33.41</td>\n",
       "      <td>3794.019452</td>\n",
       "      <td>3.85</td>\n",
       "      <td>243.218414</td>\n",
       "      <td>POLYGON ((408736.142 5692125.831, 408767.450 5...</td>\n",
       "      <td>267.290745</td>\n",
       "      <td>13.939877</td>\n",
       "      <td>398763.981752</td>\n",
       "      <td>5.688815e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Ost</td>\n",
       "      <td>2702</td>\n",
       "      <td>114.56</td>\n",
       "      <td>4945.945638</td>\n",
       "      <td>0.60</td>\n",
       "      <td>762.365790</td>\n",
       "      <td>POLYGON ((413698.678 5674573.351, 413686.981 5...</td>\n",
       "      <td>236.609842</td>\n",
       "      <td>48.670841</td>\n",
       "      <td>410803.924166</td>\n",
       "      <td>5.679526e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Süd</td>\n",
       "      <td>2703</td>\n",
       "      <td>392.75</td>\n",
       "      <td>4365.001441</td>\n",
       "      <td>381.91</td>\n",
       "      <td>1973.920712</td>\n",
       "      <td>POLYGON ((377329.166 5657157.286, 377285.838 5...</td>\n",
       "      <td>572.408624</td>\n",
       "      <td>135.333391</td>\n",
       "      <td>391122.095938</td>\n",
       "      <td>5.666630e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>2704</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>MULTIPOLYGON (((378097.915 5695126.311, 378079...</td>\n",
       "      <td>378.290040</td>\n",
       "      <td>9.558803</td>\n",
       "      <td>384941.585540</td>\n",
       "      <td>5.684987e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>2791</td>\n",
       "      <td>22.80</td>\n",
       "      <td>4255.041515</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3650.063576</td>\n",
       "      <td>POLYGON ((389635.997 5699901.234, 389648.747 5...</td>\n",
       "      <td>551.166620</td>\n",
       "      <td>4.849713</td>\n",
       "      <td>388723.285894</td>\n",
       "      <td>5.687100e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Süd</td>\n",
       "      <td>2792</td>\n",
       "      <td>411.13</td>\n",
       "      <td>4543.837549</td>\n",
       "      <td>381.83</td>\n",
       "      <td>1975.417673</td>\n",
       "      <td>POLYGON ((378695.051 5678837.912, 378676.082 5...</td>\n",
       "      <td>578.545545</td>\n",
       "      <td>137.060947</td>\n",
       "      <td>391113.136653</td>\n",
       "      <td>5.666717e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Nord</td>\n",
       "      <td>2793</td>\n",
       "      <td>143.31</td>\n",
       "      <td>5780.407594</td>\n",
       "      <td>1.09</td>\n",
       "      <td>768.093453</td>\n",
       "      <td>POLYGON ((418952.942 5692288.782, 418909.147 5...</td>\n",
       "      <td>325.119391</td>\n",
       "      <td>44.414453</td>\n",
       "      <td>408599.357355</td>\n",
       "      <td>5.680757e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county_name fdist_name  fdist_id  area_nse    area_nsne  area_se  \\\n",
       "36      Meißen     M Nord      2701     33.41  3794.019452     3.85   \n",
       "31      Meißen      M Ost      2702    114.56  4945.945638     0.60   \n",
       "4       Meißen      M Süd      2703    392.75  4365.001441   381.91   \n",
       "14      Meißen     M West      2704     36.08  1499.801018     0.08   \n",
       "54      Meißen     M West      2791     22.80  4255.041515     3.93   \n",
       "55      Meißen      M Süd      2792    411.13  4543.837549   381.83   \n",
       "53      Meißen     M Nord      2793    143.31  5780.407594     1.09   \n",
       "\n",
       "       area_sne                                           geometry  \\\n",
       "36   243.218414  POLYGON ((408736.142 5692125.831, 408767.450 5...   \n",
       "31   762.365790  POLYGON ((413698.678 5674573.351, 413686.981 5...   \n",
       "4   1973.920712  POLYGON ((377329.166 5657157.286, 377285.838 5...   \n",
       "14  3411.198775  MULTIPOLYGON (((378097.915 5695126.311, 378079...   \n",
       "54  3650.063576  POLYGON ((389635.997 5699901.234, 389648.747 5...   \n",
       "55  1975.417673  POLYGON ((378695.051 5678837.912, 378676.082 5...   \n",
       "53   768.093453  POLYGON ((418952.942 5692288.782, 418909.147 5...   \n",
       "\n",
       "    area_fdist  endangered_forest_density  centroid_xcoord  centroid_ycoord  \n",
       "36  267.290745                  13.939877    398763.981752     5.688815e+06  \n",
       "31  236.609842                  48.670841    410803.924166     5.679526e+06  \n",
       "4   572.408624                 135.333391    391122.095938     5.666630e+06  \n",
       "14  378.290040                   9.558803    384941.585540     5.684987e+06  \n",
       "54  551.166620                   4.849713    388723.285894     5.687100e+06  \n",
       "55  578.545545                 137.060947    391113.136653     5.666717e+06  \n",
       "53  325.119391                  44.414453    408599.357355     5.680757e+06  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts[districts['county_name'] == 'Meißen'].sort_values('fdist_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the different datasets\n",
    "\n",
    "For this project there are three different data sources. \n",
    "\n",
    "The data sources are:\n",
    "1. **The infestation history**\n",
    "    * contains all observations for the amount of damaged wood (target variable)\n",
    "    * also contains the timeframe for these observations, the respective forestry district, the type of forest (sepeartion by private/state owned) and the amount of refurbished wood in this time period\n",
    "    * data supplied by Sachsenforst\n",
    "    * already read in and stored in the infestation_history dataframe\n",
    "\n",
    "\n",
    "2. **Information on the forestry districts (new and old)**\n",
    "    * contains the geodata (polygons) of these districts\n",
    "    * also for every district contains the area covered by forest, separated by private/state owned forest as well as endangered and safe forest area (endangered are only sections that consist predominantely of adult spruce trees)\n",
    "    * data supplied by Sachsenforst\n",
    "    * already read in and stored in the districts geodataframe\n",
    "\n",
    "\n",
    "3. **Meteorological raster data**\n",
    "    * contain certain climatic parameters such as the maximum, mean, minimum temperature, humidity, wind speeds etc. (15 variables total)\n",
    "    * one raster file for every variable and every day of the covered time period (from January 2006 up to February 2020, so more than 80,000 files)\n",
    "    * 5000mx5000m raster\n",
    "    * supplied by ReKIS (*Regionales Klima-Informationssystem Sachsen, Sachsen-Anhalt und Thüringen*, https://rekis.hydro.tu-dresden.de/)\n",
    "\n",
    "To make sense of the data we will have to aggregate this information into a single dataframe that can be used for an EDA and the modeling process. This will be done in the following sections.\n",
    "\n",
    "The data aggreagtion will take place in a function that iterates over the rows (observations) of our infestation_history dataframe and supplements them with the information from the other data sources. The infestation_history dataframe was chosen as the skeleton on which information is added on because of the iterative nature of the data science life cycle. In case we later drop observations from the get go, create new synthetic observations or engineer our features differently, we need to ensure that this function still operates as expected. Thus the approach of taking infestation_history as the base and then specifying what to do with the rest of the data for every observation was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially 839 observations with neither infested wood nor disposed wood (out of 8008 toal observations).\n"
     ]
    }
   ],
   "source": [
    "# how many zero rows do we already have?\n",
    "n_zrows = infestation_history[(infestation_history['infested_wood'] == 0) & (infestation_history['disposed_wood'] == 0)].shape[0]\n",
    "print(f'Initially {n_zrows} observations with neither infested wood nor disposed wood (out of {infestation_history.shape[0]} toal observations).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Kommentieren\n",
    "districts_before_jul2013 = pd.concat([districts_old, districts_new[(districts_new['county_name'] != 'Erzgebirgskreis') & (districts_new['county_name'] != 'Meißen')]], axis=0)\n",
    "districts_jul2013_sep2014 = pd.concat([districts_old[districts_old['county_name'] == 'Erzgebirgskreis'], districts_new[districts_new['county_name'] != 'Erzgebirgskreis']], axis=0)\n",
    "districts_after_sep2014 = districts_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_row(obs, district, year, timeframe, forest_type):\n",
    "    '''\n",
    "    TODO: Add description\n",
    "    '''\n",
    "    # first check if there already is an observation for this combination of parameters    \n",
    "    if not (\n",
    "        (obs['fdist_id'] == district) & \n",
    "        (obs['year'] == year) &\n",
    "        (obs['timeframe'] == timeframe) &\n",
    "        (obs['forest_ownership'] == forest_type)\n",
    "    ).any():\n",
    "        \n",
    "        # if there is no observation yet: create one with damaged wood (infested_wood) and restored wood (disposed_wood) of 0\n",
    "        return {\n",
    "            'fdist_id': district, \n",
    "            'year': year,\n",
    "            'timeframe': timeframe,\n",
    "            'forest_ownership': forest_type,\n",
    "            'infested_wood': 0,\n",
    "            'disposed_wood': 0\n",
    "        } \n",
    "\n",
    "\n",
    "def zero_fill(obs=infestation_history, \n",
    "              districts_before_jul2013=districts_before_jul2013, \n",
    "              districts_jul2013_sep2014=districts_jul2013_sep2014, \n",
    "              districts_after_sep2014=districts_after_sep2014):\n",
    "    '''\n",
    "    TODO: Add description\n",
    "    '''\n",
    "    \n",
    "    # print current number of rows\n",
    "    print(f'Number of rows before zero_fill(): {obs.shape[0]}')\n",
    "    \n",
    "    # to check every valid combination of timeframes, forest types, years and districts we use nested loops\n",
    "    # loop through all unique months and quarters\n",
    "    for timeframe in obs['timeframe'].unique():\n",
    "        \n",
    "        # loop through both types of forest (state owned - SW, private - NSW)\n",
    "        for forest_type in obs['forest_ownership'].unique():\n",
    "            \n",
    "            # loop through all years\n",
    "            for year in range(2005, 2021):\n",
    "                \n",
    "                # depending on the year there were different forestry districts\n",
    "                # we check which year it is via an if-statement\n",
    "                if year < 2013 or (year == 2013 and timeframe in ['01 Januar-März', '04 April', '05 Mai', '06 Juni']):\n",
    "                    \n",
    "                    # loop only through the old districts before July 2013\n",
    "                    for district in districts_before_jul2013['fdist_id'].unique():\n",
    "                    \n",
    "                        # create new row if conditions are met by calling create_zero_rows()\n",
    "                        obs = obs.append(\n",
    "                            create_zero_row(obs, district, year, timeframe, forest_type),\n",
    "                            ignore_index=True)\n",
    "                    \n",
    "                elif year == 2013 or (year == 2014 and not timeframe == '10 Oktober-Dezember'):\n",
    "                    \n",
    "                    # loop only through the districts from July 2013 until December 2014\n",
    "                    for district in districts_jul2013_sep2014['fdist_id'].unique():\n",
    "                    \n",
    "                        # create new row if conditions are met by calling create_zero_rows()\n",
    "                        obs = obs.append(\n",
    "                            create_zero_row(obs, district, year, timeframe, forest_type),\n",
    "                            ignore_index=True)\n",
    "                        \n",
    "                elif year >= 2014:\n",
    "\n",
    "                    # additionial check to ensure we do not add rows after september 2020 (end of observations)\n",
    "                    if not (year == 2020 and timeframe == '10 Oktober-Dezember'):\n",
    "                        \n",
    "                        # loop only through the new districts after 2014\n",
    "                        for district in districts_after_sep2014['fdist_id'].unique():\n",
    "                            \n",
    "                            # create new row if conditions are met by calling create_zero_rows()\n",
    "                            obs = obs.append(\n",
    "                                create_zero_row(obs, district, year, timeframe, forest_type),\n",
    "                                ignore_index=True)\n",
    "       \n",
    "    # reset the index\n",
    "    obs.reset_index(inplace=True, drop=True)  \n",
    "    \n",
    "    # print new number of rows\n",
    "    print(f'Number of rows after zero_fill(): {obs.shape[0]}')\n",
    "          \n",
    "    return obs\n",
    "\n",
    "# TODO: replace if statements with mapping dictionairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before zero_fill(): 8008\n",
      "Number of rows after zero_fill(): 13485\n"
     ]
    }
   ],
   "source": [
    "infestation_history = zero_fill(infestation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12637"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 53 * 8 * 12 # \n",
    "d = 53 * 5 # 2013\n",
    "b = 54 * 11 # 2013/2014\n",
    "c = 53 * 7 #2020\n",
    "\n",
    "\n",
    "2*(d+a+b+c)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge information on the forestry districts with the obersvations in infestation_history\n",
    "# TODO: wenn Exceldatei nicht stimmt, dann ist dieser Merge falsch, weil Führungsneun-nummern aus altem shapefile dann nicht mit Excel-Führungsneun-nummern übereinstimmen\n",
    "infestation_history = pd.merge(infestation_history, districts[['county_name', 'fdist_name', 'area_nse', 'area_nsne', 'area_se', 'area_sne', 'fdist_id', 'centroid_xcoord', 'centroid_ycoord', 'area_fdist', 'endangered_forest_density']], on='fdist_id')\n",
    "\n",
    "# save geodataframe as shape file \n",
    "districts.to_file('forestry_districts.shp', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nansumwrapper(a, **kwargs):\n",
    "    '''\n",
    "    TODO: documentation\n",
    "    '''\n",
    "    if np.isnan(a).all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nansum(a, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_mean(filename, polygons):\n",
    "    '''\n",
    "    This function calculates the mean of a target meteorological parameter for a specific polygon over a given timeframe. \n",
    "    This is done by masking the rasters with the polygon and using the masked raster points to calculate the mean.\n",
    "\n",
    "    inputs:\n",
    "        - raster_dir: directory where all meteorological raster files are stored\n",
    "        - polygon: shape of the forestry district\n",
    "        - parameter_name: the shorthand for the meteorological parameter (needs to match the shorthand in the raster file names)\n",
    "        - year: the year of the obervation\n",
    "        - timeframe: the timeframe of the observation, formatted in a way that the glob() function can identify the right files based on a pattern match (example: '0[1-3]' for january-march)\n",
    "        \n",
    "    returns:\n",
    "        - the mean value of the meteorological parameter for the timeframe in the specified forestry district\n",
    "    '''  \n",
    "    # TODO: Workaround entfernen wenn alle Datein vorhanden oder print-Befehl einbauen, sodass man benachrichtigt wird welches file fehlt\n",
    "    try:\n",
    "        current_raster = rasterio.open(filename, nodata=-9999.0)\n",
    "    except: \n",
    "        return [np.nan for i in range(polygons.shape[0])] \n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for polygon in polygons['geometry']:\n",
    "        # mask raster with polygon and read in the relevant raster points\n",
    "        masked, mask_transform = mask(\n",
    "            dataset=current_raster, \n",
    "            shapes=[polygon], \n",
    "            crop=True, # avoids loading in the whole raster\n",
    "            filled=False, # mask outside values with nodata instead of 0, so we can safely compute zonal stats\n",
    "            all_touched=True # we can chose to overfill or underfill the polygon, in this case we overfill\n",
    "        ) \n",
    "        results.append(np.ma.mean(masked))\n",
    "    \n",
    "    # since we want to return the mean of the parameter over the whole timeframe we return the arithmetic mean of the list of daily values\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with year 2005, elapsed time: 0.0 min\n",
      "Starting with year 2006, elapsed time: 1.57 min\n",
      "Starting with year 2007, elapsed time: 3.15 min\n",
      "Starting with year 2008, elapsed time: 4.74 min\n",
      "Starting with year 2009, elapsed time: 6.34 min\n",
      "Starting with year 2010, elapsed time: 7.92 min\n",
      "Starting with year 2011, elapsed time: 9.52 min\n",
      "Starting with year 2012, elapsed time: 11.11 min\n",
      "Starting with year 2013, elapsed time: 12.72 min\n",
      "Starting with year 2014, elapsed time: 14.32 min\n",
      "Starting with year 2015, elapsed time: 15.89 min\n",
      "Starting with year 2016, elapsed time: 17.33 min\n",
      "Starting with year 2017, elapsed time: 18.79 min\n",
      "Starting with year 2018, elapsed time: 20.24 min\n",
      "Starting with year 2019, elapsed time: 21.69 min\n",
      "Starting with year 2020, elapsed time: 23.15 min\n",
      "Finished aggregation, total time: 23.4 min\n"
     ]
    }
   ],
   "source": [
    "# specify location of raster files\n",
    "raster_dir=r'data_raw/climate_monthly_1000/'\n",
    "\n",
    "# the obervations from april untill september are gathered monthly while they are gathered quarterly from october till march\n",
    "# create a dictionairy that maps the timeframe values from infestation_history to the pattern that is used in the raster file names \n",
    "timeframe_dict = {\n",
    "'01 Januar-März': ['01', '02', '03'],\n",
    "'04 April': ['04'],\n",
    "'05 Mai': ['05'],\n",
    "'06 Juni': ['06'],\n",
    "'07 Juli': ['07'],\n",
    "'08 August': ['08'],\n",
    "'09 September': ['09'],\n",
    "'10 Oktober-Dezember': ['10', '11', '12']\n",
    "}\n",
    "\n",
    "# create a dictionary of all meteorological parameter shorthands to calculate\n",
    "# these shorthands match the notation used in the respective filenames\n",
    "# they are mapped to the respective aggregation function that will be used if there are multiple months in the timeframe\n",
    "# for example we want the average temperature but the total amount of sunshine hours\n",
    "parameter_info = {\n",
    "    'TX0' : np.nanmean, # maximum temperature of the day in degrees Celsius\n",
    "    'TM0' : np.nanmean, # mean temperature of the day in degrees Celsius\n",
    "    'TN0' : np.nanmean, # minimum temperature of the day in degrees Celsius\n",
    "    'RF0' : np.nanmean, # mean relative humidity of the day in %\n",
    "    'SD0' : nansumwrapper, # total sunshine duration of the day in h\n",
    "    'RRU' : nansumwrapper, # total precipitation of the day in mm\n",
    "    'RRK' : nansumwrapper, # corrected total precipitation of the day in mm (corrects systematic errors of the measuring device and installation location such as wetting/evaporation losses)\n",
    "    'FF1' : np.nanmean, # mean wind velocity of the day 10 metres above ground in m*s-1\n",
    "    'FF2' : np.nanmean, # mean wind velocity of the day 2 metres above ground in m*s-1\n",
    "    'FFB' : np.nanmean, # wind speed of the day on the beaufort scale in bft\n",
    "    'RGK' : nansumwrapper, # total global solar irradiation of the day in kWh*m-2\n",
    "    'ETP' : nansumwrapper, # potential evaporation for the day in mm\n",
    "    'GRV' : nansumwrapper, # potential evapotranspiration for the day in mm\n",
    "    'KWU' : nansumwrapper,\n",
    "    'KWK' : nansumwrapper\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# since this will take a while we track the time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# we do not want to append to dataframes and thus use a list of lists \n",
    "# (one list for every parameter and a final list that will be used for merging)\n",
    "climate_res = [[] for _ in range(len(parameter_info) + 1)]\n",
    "\n",
    "\n",
    "for current_year in np.sort(infestation_history['year'].unique()):\n",
    "    \n",
    "    elapsed_time = round((time.time() - start_time)/60, 2)\n",
    "    print(f'Starting with year {current_year}, elapsed time: {elapsed_time} min')\n",
    "    \n",
    "    polygons = districts[['fdist_id', 'geometry']] if current_year <= 2014 else districts_new[['fdist_id', 'geometry']]\n",
    "    \n",
    "    for current_timeframe in timeframe_dict:\n",
    "        for idx, current_parameter in enumerate(parameter_info):\n",
    "            \n",
    "            filenames = [fr'{raster_dir}GRID_1_Messungen_Tageswerte_2020_{current_parameter}_MW_{current_year}{current_month}00_utm.asc' for current_month in timeframe_dict.get(current_timeframe)]\n",
    "             \n",
    "            aggregation_results = [raster_mean(filename, polygons) for filename in filenames]\n",
    "            \n",
    "            results_after_dispatch = [parameter_info[current_parameter](x) for x in zip(*aggregation_results)]\n",
    "            \n",
    "            climate_res[idx].extend(results_after_dispatch)         \n",
    "        \n",
    "        \n",
    "        merge_dummies = [f'{current_year}-{current_timeframe}-{dist}' for dist in polygons['fdist_id']]\n",
    "        climate_res[-1].extend(merge_dummies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "climate_res = pd.DataFrame(climate_res).T\n",
    "\n",
    "climate_res.columns = [*parameter_info, 'merge_dummy']\n",
    "\n",
    "print(f'Finished aggregation, total time: {round((time.time()-start_time)/60, 2)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['merge_dummy'] = infestation_history['year'].map(lambda x: str(x) + '-') + infestation_history['timeframe'].map(lambda x: x + '-') + infestation_history['fdist_id'].astype(str)\n",
    "\n",
    "infestation_history = pd.merge(\n",
    "    infestation_history, \n",
    "    climate_res, \n",
    "    on='merge_dummy'\n",
    ").drop('merge_dummy', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County/District names, ID, timestamp - preparation for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetzt ID über Namen, daher Führungsneun austauschen nicht mehr notwendig\n",
    "# def connect_districts(district):\n",
    "#     district = str(district)\n",
    "#     return int(\n",
    "#         (\n",
    "#             district[:2] + \n",
    "#             district[2].replace('9','0') + \n",
    "#             district[3]\n",
    "#         ).replace('2108', '2198') # special case 2198 (Schwarzenberg), does not exist in new structure, so we leave it as is\n",
    "#     )\n",
    "\n",
    "# infestation_history['query'] = infestation_history['fdist_id'].apply(lambda x: connect_districts(x))\n",
    "# infestation_history = pd.merge(infestation_history, districts[['county_name', 'fdist_name', 'fdist_id']], left_on='query', right_on='fdist_id', suffixes=('','_drop'))\n",
    "# infestation_history.drop(['query', 'fdist_id_drop'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# for Meißen, logically connect the old forestry districts to the new ones that best approxiamte the location/shape\n",
    "def connect_districts(fdist_name, fdist_id):\n",
    "    if not fdist_id in [2793, 2791]:\n",
    "        return fdist_name\n",
    "    \n",
    "    else:\n",
    "        return fdist_name.replace(\n",
    "            'Nord', 'Ost' # what was M Nord is almost exactly M Ost in the new structure\n",
    "        ).replace(\n",
    "            'West', 'Nord' # M West is best approximated by M Nord in the new structure\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['fdist_newname'] = infestation_history[['fdist_name','fdist_id']].apply(lambda x: connect_districts(x[0], x[1]), axis=1)\n",
    "infestation_history['id'] = infestation_history['county_name'].map(lambda x: x + '-') + infestation_history['fdist_newname'].map(lambda x: x + '-') + infestation_history['forest_ownership']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_timeframe = {\n",
    "    '01 Januar-März': '-03-31',\n",
    "    '04 April': '-04-30',\n",
    "    '05 Mai': '-05-31',\n",
    "    '06 Juni': '-06-30',\n",
    "    '07 Juli': '-07-31',\n",
    "    '08 August': '-08-31',\n",
    "    '09 September': '-09-30',\n",
    "    '10 Oktober-Dezember': '-12-31'\n",
    "    }\n",
    "             \n",
    "     \n",
    "infestation_history['timestamp'] = infestation_history['year'].astype(str) + infestation_history['timeframe'].map(lambda x: end_of_timeframe.get(x))\n",
    "infestation_history['timestamp'] = pd.to_datetime(infestation_history['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounting for previously disposed wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "\n",
    "\n",
    "# for every row map the 'disposed_wood' and 'infested_wood' value of the previous observation with the same 'id'\n",
    "# TODO: documentation\n",
    "\n",
    "prev_disposed_wood = []\n",
    "prev_infested_wood = []\n",
    "\n",
    "for i, row in infestation_history.iterrows():\n",
    "    if row['timestamp'].month in range(4,10):\n",
    "        previous_row = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-1)) & \n",
    "            (infestation_history['id'] == row['id'])\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        previous_row = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-3)) & \n",
    "            (infestation_history['id'] == row['id'])\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    pdw = previous_row['disposed_wood'].values\n",
    "    piw = previous_row['infested_wood'].values\n",
    "    \n",
    "    prev_disposed_wood.append(pdw[0] if len(pdw)==1 else np.NaN)\n",
    "    prev_infested_wood.append(piw[0] if len(piw)==1 else np.NaN)\n",
    "    \n",
    "infestation_history['prev_disposed_wood'] = prev_disposed_wood\n",
    "infestation_history['prev_infested_wood'] = prev_infested_wood\n",
    "\n",
    "infestation_history['delta_prev_inf_dis'] = infestation_history['prev_infested_wood'] - infestation_history['prev_disposed_wood'] \n",
    "infestation_history.drop('prev_disposed_wood', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages of climate features for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingyr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollyr' for name in parameter_info], \n",
    "                                   'prev_infested_wood_rollyr'])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([1 if element.month in range(4, 10) else 3 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollyr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollyr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/12\n",
    "        )\n",
    "    # also do this for prev_infested_wood\n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'prev_infested_wood_rollyr'\n",
    "    ] = id_subset['prev_infested_wood'].rolling(8).sum()\n",
    "                          \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingsr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollsr' for name in parameter_info], \n",
    "                                   'prev_infested_wood_rollsr'])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([1 if element.month in range(4, 10) else 0 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollsr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollsr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/6\n",
    "        )\n",
    "    # also do this for prev_infested_wood\n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'prev_infested_wood_rollsr'\n",
    "    ] = id_subset['prev_infested_wood'].rolling(8).sum()\n",
    "                          \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingwr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollwr' for name in parameter_info], \n",
    "                                   'prev_infested_wood_rollwr'])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([0 if element.month in range(4, 10) else 1 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollwr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollwr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/6\n",
    "        )\n",
    "    # also do this for prev_infested_wood\n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'prev_infested_wood_rollwr'\n",
    "    ] = id_subset['prev_infested_wood'].rolling(8).sum()\n",
    "                          \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endangered area for this id\n",
    "data['area_endangered'] = data[['forest_ownership', 'area_nse', 'area_se']].apply(lambda x: x[1] if x[0] == 'NSW' else x[2], axis=1)\n",
    "\n",
    "# todo: endangered area for this fdist, other forest ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windfall and demolition wood \n",
    "\n",
    "Abiotic damages - Bruch & Wurf, Schnee,Eis u. Sturm kombiniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1945 entries, 0 to 1944\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   county_acronym            1945 non-null   object \n",
      " 1   county_nr                 1945 non-null   int64  \n",
      " 2   fdist_nr                  1945 non-null   int64  \n",
      " 3   fdist_id                  1945 non-null   int64  \n",
      " 4   year                      1945 non-null   int64  \n",
      " 5   timeframe                 1945 non-null   object \n",
      " 6   forest_ownership          1945 non-null   object \n",
      " 7   damaged_wood              1945 non-null   float64\n",
      " 8   disposed_demolition_wood  1945 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 136.9+ KB\n"
     ]
    }
   ],
   "source": [
    "demolition_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data set\n",
    "demolition_history = pd.read_excel(r'data_raw/ML_WB_20201112.xlsx', \n",
    "                                    names=['county_acronym', 'county_nr', 'fdist_nr', 'fdist_id','year', \n",
    "                                           'timeframe', 'forest_ownership', 'damaged_wood', 'disposed_demolition_wood'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the fruits of our labor and merge fdist_ids on fdist_newname to logically connect old and new districts\n",
    "demolition_history = pd.merge(demolition_history, infestation_history[['fdist_id', 'fdist_newname']], on='fdist_id')\n",
    "\n",
    "# fill zero rows\n",
    "\n",
    "# fill all other timeframes except April and September with the right values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13485 entries, 0 to 13484\n",
      "Data columns (total 84 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   fdist_id                   13485 non-null  int64         \n",
      " 1   year                       13485 non-null  int64         \n",
      " 2   timeframe                  13485 non-null  object        \n",
      " 3   forest_ownership           13485 non-null  object        \n",
      " 4   infested_wood              13485 non-null  float64       \n",
      " 5   disposed_wood              13485 non-null  float64       \n",
      " 6   county_name                13485 non-null  object        \n",
      " 7   fdist_name                 13485 non-null  object        \n",
      " 8   area_nse                   13485 non-null  float64       \n",
      " 9   area_nsne                  13485 non-null  float64       \n",
      " 10  area_se                    13485 non-null  float64       \n",
      " 11  area_sne                   13485 non-null  float64       \n",
      " 12  centroid_xcoord            13485 non-null  float64       \n",
      " 13  centroid_ycoord            13485 non-null  float64       \n",
      " 14  area_fdist                 13485 non-null  float64       \n",
      " 15  endangered_forest_density  13485 non-null  float64       \n",
      " 16  TX0                        12848 non-null  object        \n",
      " 17  TM0                        12848 non-null  object        \n",
      " 18  TN0                        12848 non-null  object        \n",
      " 19  RF0                        12848 non-null  object        \n",
      " 20  SD0                        12848 non-null  object        \n",
      " 21  RRU                        12848 non-null  object        \n",
      " 22  RRK                        12848 non-null  object        \n",
      " 23  FF1                        12848 non-null  object        \n",
      " 24  FF2                        12848 non-null  object        \n",
      " 25  FFB                        12848 non-null  object        \n",
      " 26  RGK                        12848 non-null  object        \n",
      " 27  ETP                        12848 non-null  object        \n",
      " 28  GRV                        12848 non-null  object        \n",
      " 29  KWU                        12848 non-null  object        \n",
      " 30  KWK                        12848 non-null  object        \n",
      " 31  fdist_newname              13485 non-null  object        \n",
      " 32  id                         13485 non-null  object        \n",
      " 33  timestamp                  13485 non-null  datetime64[ns]\n",
      " 34  prev_infested_wood         13377 non-null  float64       \n",
      " 35  delta_prev_inf_dis         13377 non-null  float64       \n",
      " 36  TX0_rollyr                 12092 non-null  float64       \n",
      " 37  TM0_rollyr                 12092 non-null  float64       \n",
      " 38  TN0_rollyr                 12092 non-null  float64       \n",
      " 39  RF0_rollyr                 12092 non-null  float64       \n",
      " 40  SD0_rollyr                 12092 non-null  float64       \n",
      " 41  RRU_rollyr                 12092 non-null  float64       \n",
      " 42  RRK_rollyr                 12092 non-null  float64       \n",
      " 43  FF1_rollyr                 12092 non-null  float64       \n",
      " 44  FF2_rollyr                 12092 non-null  float64       \n",
      " 45  FFB_rollyr                 12092 non-null  float64       \n",
      " 46  RGK_rollyr                 12092 non-null  float64       \n",
      " 47  ETP_rollyr                 12092 non-null  float64       \n",
      " 48  GRV_rollyr                 12092 non-null  float64       \n",
      " 49  KWU_rollyr                 12092 non-null  float64       \n",
      " 50  KWK_rollyr                 12092 non-null  float64       \n",
      " 51  prev_infested_wood_rollyr  12621 non-null  float64       \n",
      " 52  TX0_rollsr                 12092 non-null  float64       \n",
      " 53  TM0_rollsr                 12092 non-null  float64       \n",
      " 54  TN0_rollsr                 12092 non-null  float64       \n",
      " 55  RF0_rollsr                 12092 non-null  float64       \n",
      " 56  SD0_rollsr                 12092 non-null  float64       \n",
      " 57  RRU_rollsr                 12092 non-null  float64       \n",
      " 58  RRK_rollsr                 12092 non-null  float64       \n",
      " 59  FF1_rollsr                 12092 non-null  float64       \n",
      " 60  FF2_rollsr                 12092 non-null  float64       \n",
      " 61  FFB_rollsr                 12092 non-null  float64       \n",
      " 62  RGK_rollsr                 12092 non-null  float64       \n",
      " 63  ETP_rollsr                 12092 non-null  float64       \n",
      " 64  GRV_rollsr                 12092 non-null  float64       \n",
      " 65  KWU_rollsr                 12092 non-null  float64       \n",
      " 66  KWK_rollsr                 12092 non-null  float64       \n",
      " 67  prev_infested_wood_rollsr  12621 non-null  float64       \n",
      " 68  TX0_rollwr                 12092 non-null  float64       \n",
      " 69  TM0_rollwr                 12092 non-null  float64       \n",
      " 70  TN0_rollwr                 12092 non-null  float64       \n",
      " 71  RF0_rollwr                 12092 non-null  float64       \n",
      " 72  SD0_rollwr                 12092 non-null  float64       \n",
      " 73  RRU_rollwr                 12092 non-null  float64       \n",
      " 74  RRK_rollwr                 12092 non-null  float64       \n",
      " 75  FF1_rollwr                 12092 non-null  float64       \n",
      " 76  FF2_rollwr                 12092 non-null  float64       \n",
      " 77  FFB_rollwr                 12092 non-null  float64       \n",
      " 78  RGK_rollwr                 12092 non-null  float64       \n",
      " 79  ETP_rollwr                 12092 non-null  float64       \n",
      " 80  GRV_rollwr                 12092 non-null  float64       \n",
      " 81  KWU_rollwr                 12092 non-null  float64       \n",
      " 82  KWK_rollwr                 12092 non-null  float64       \n",
      " 83  prev_infested_wood_rollwr  12621 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(60), int64(2), object(21)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "infestation_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history.to_csv('barkbeetle_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barkbeetle_dataset.dropna(inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
