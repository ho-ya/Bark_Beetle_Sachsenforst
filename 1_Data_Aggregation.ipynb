{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spruce Bark Beetle Prediction - Data Aggreation\n",
    "\n",
    "#### Modeling the spruce bark beetle infestation for given spatial administrative units within Saxony and for distictive time intervals on the basis of the infestation development and the weather pattern up to the time of the forecast\n",
    "\n",
    "**by**\n",
    "Yannic Holländer\n",
    "\n",
    "**Abstract**\n",
    "This notebook encompasses the merging of various data sources. We create a single dataset containing all relevant information on the bark beetle infestation in Saxony. Subsequent notebooks use this dataset for the exploratory data analysis and model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview of available data\n",
    "\n",
    "For this project there are four main data sources. These data sources are:\n",
    "\n",
    "1. **The infestation history**\n",
    "    * contains all observations for the amount of accrued infested wood (target variable, in solid m$^3$)\n",
    "    * also contains the timeframe for these observations, the respective forestry district, the type of forest (sepeartion by private/state owned) and the amount of disposed wood in this time period\n",
    "    * data supplied by *Staatsbetrieb Sachsenforst*\n",
    "\n",
    "\n",
    "2. **Information on the forestry districts**\n",
    "    * contrary to previous approaches, we are predicting the amount of infested wood not for the whole state of Saxony, but for given spatial administrative units - forestry districts - of which there currently are 53\n",
    "    * contains the geodata/polygons for these districts\n",
    "    * also for every district, contains the area covered by forest, separated by private/state owned forest as well as endangered and safe forest area (endangered are only sections that consist predominantely of adult spruce trees)\n",
    "    * the forestry district borders changed slightly in 2013/2014, we have the shape of the old districts as well as the new districts\n",
    "    * data supplied by *Staatsbetrieb Sachsenforst*\n",
    "\n",
    "\n",
    "3. **Meteorological raster data**\n",
    "    * contain certain climatic parameters such as the mean temperature, humidity, wind speeds, global irridiation etc. (15 variables total)\n",
    "    * one raster file for every variable and month/day of the covered time period (from 2005 up to February 2020)\n",
    "    * 1000mx1000m raster\n",
    "    * supplied by ReKIS (*Regionales Klima-Informationssystem Sachsen, Sachsen-Anhalt und Thüringen*, https://rekis.hydro.tu-dresden.de/)\n",
    "    \n",
    "    \n",
    "4. **Information on abiotic damages**\n",
    "    * covers windfall and demolition wood, damages from drought, storm, ice, snow etc.\n",
    "    * gathered semi-anually (april and september)\n",
    "    * similar variables to infestation_history\n",
    "    * data supplied by *Staatsbetrieb Sachsenforst*\n",
    "    \n",
    "To make sense of the data we will have to aggregate this information into a single dataframe that can be used for an EDA and the modeling process. \n",
    "\n",
    "\n",
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import rasterio \n",
    "import rasterio.plot\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# diplay all columns of a dataframe\n",
    "pd.options.display.max_columns= None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the infestation history dataset, which was supplied as a Microsoft Excel file. We use it as a skeleton on which information from the other sources is added on. This way we build our dataset on top of central observations of the target variable. It has the following columns:\n",
    "\n",
    "* **county_acronym** - A shorthand of the respective county. The 53 forestry districts form the 13 counties of the free state of Saxony. \n",
    "* **county_nr** - The number of the respective county. Every county has a unique double-digit number.\n",
    "* **fdist_nr** - Denotes the forestry district within the county. In combination with county_nr makes up the unique identifier for forestry districts (fdist_id)\n",
    "* **fdist_id** - Unique identifier for the forestry district. Has four digits. The first two digits are made up of county_nr and the last two are made up of fdist_nr.\n",
    "* **year** - Year of the observation. Ranges from 2006 until 2020. Last observation is from September 2020\n",
    "* **timeframe** - The timeframe of the observation within the year. The data is gathered monthly from April till September and quarterly from October till March.\n",
    "* **forest_ownership** - A binary categorial variable that distinguishes between state owned forest (SW) and private/corporate forest (NSW)\n",
    "* **infested_wood** - Target variable. The amount of accrued infested wood in solid cubic metres. \n",
    "* **disposed_wood** - Infested wood that was disposed, i.e. the infested trees were cut down and removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_acronym</th>\n",
       "      <th>county_nr</th>\n",
       "      <th>fdist_nr</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>forest_ownership</th>\n",
       "      <th>infested_wood</th>\n",
       "      <th>disposed_wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>06 Juni</td>\n",
       "      <td>SW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>08 August</td>\n",
       "      <td>SW</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2007</td>\n",
       "      <td>10 Oktober-Dezember</td>\n",
       "      <td>SW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2008</td>\n",
       "      <td>04 April</td>\n",
       "      <td>SW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BZ</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2501</td>\n",
       "      <td>2008</td>\n",
       "      <td>06 Juni</td>\n",
       "      <td>SW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  county_acronym  county_nr  fdist_nr  fdist_id  year            timeframe  \\\n",
       "0             BZ         25         1      2501  2007              06 Juni   \n",
       "1             BZ         25         1      2501  2007            08 August   \n",
       "2             BZ         25         1      2501  2007  10 Oktober-Dezember   \n",
       "3             BZ         25         1      2501  2008             04 April   \n",
       "4             BZ         25         1      2501  2008              06 Juni   \n",
       "\n",
       "  forest_ownership  infested_wood  disposed_wood  \n",
       "0               SW            5.0            0.0  \n",
       "1               SW           12.0           12.0  \n",
       "2               SW            2.0            0.0  \n",
       "3               SW            1.0            0.0  \n",
       "4               SW            2.0            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the infestation history data\n",
    "infestation_history = pd.read_excel(\n",
    "    r'data_raw/ML_BDR_20201019.xlsx', \n",
    "    names=['county_acronym', \n",
    "           'county_nr', \n",
    "           'fdist_nr', \n",
    "           'fdist_id',\n",
    "           'year', \n",
    "           'timeframe', \n",
    "           'forest_ownership', \n",
    "           'infested_wood', \n",
    "           'disposed_wood'])\n",
    "\n",
    "# display first few rows of the dataframe\n",
    "infestation_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Forestry Districts\n",
    "## 3.1 Preparing the infestation history dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fdist_id column of our infestation_history dataframe contains a unique identifier for the forstry districts. The first two digits indicate the county (*Landkreis*) and the last two digits indicate the number of the forestry district in this county. These digits correspond to the county_nr and fdist_nr columns respectively.\n",
    "\n",
    "In some forestry districts the district number (last two digits) begins with a leading nine instead of a leading zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 1101,\n",
       "       1201, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2191, 2192, 2193,\n",
       "       2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2601, 2602,\n",
       "       2603, 2604, 2605, 2606, 2691, 2901, 2902, 2701, 2702, 2703, 2704,\n",
       "       2791, 2792, 2793, 2801, 2802, 2803, 2804, 2805, 3001, 3002, 3003,\n",
       "       2301, 2302, 2303, 2304, 2305, 2306, 2401, 2402], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all forestry district numbers\n",
    "infestation_history['fdist_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the observation timeframe, some of the forestry districts (counties *Erzgebirgskreis* and *Meißen*) underwent a restructuring process. A leading nine instead of a leading zero signifies that the border of the district was different than it is today. According to *Sachsenforst* these changes happened in July 2013 for the county *Meißen* (fdist_id 27xx) and in September 2014 for *Erzgebirgskreis* (fdist_id 21xx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fdist_id\n",
       "2191    2014\n",
       "2192    2014\n",
       "2193    2014\n",
       "2194    2014\n",
       "2195    2014\n",
       "2196    2014\n",
       "2197    2014\n",
       "2198    2014\n",
       "2691    2020\n",
       "2791    2013\n",
       "2792    2013\n",
       "2793    2013\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the max years for districts with a fdist_nr with leading nine\n",
    "infestation_history[\n",
    "    infestation_history['fdist_nr'] >= 90\n",
    "].groupby('fdist_id')['year'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two parts of 'fdist_id' also appear in the 'county_nr' and 'fdist_nr' columns seperately. Thus they are redundant. We check if the information in these three columns really is the same for every observation. If that is the case we drop 'county_nr' and 'fdist_nr':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# county_nr as as a string\n",
    "county_nr = infestation_history[\n",
    "    'county_nr'\n",
    "].astype(str) \n",
    "# fdist_nr as a string (pad with 0)\n",
    "fdist_nr = infestation_history[\n",
    "    'fdist_nr'\n",
    "].astype(str).map(lambda x: x.zfill(2)) \n",
    "\n",
    "# concatenate these strings and check if they are identical to the 'fdist_id' column at every observation\n",
    "(county_nr + fdist_nr == infestation_history['fdist_id'].astype(str)).all() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our comparison states that the columns are redunant. We drop county_nr and fdist_nr in favor of fdist_id which combines them into a single, four-digit identifier. We also drop the county_acronym column which only states the county initials of the county_nr. A full association of the forestry district and county names is found in the forestry district geodata which we will load in later. For now the fdist_id countains all information we need in this dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'county_nr' and 'fdist_nr' columns \n",
    "# because the information is also found in 'fdist_id'\n",
    "infestation_history.drop(\n",
    "    [\n",
    "        'county_nr', \n",
    "        'fdist_nr', \n",
    "        'county_acronym'\n",
    "    ], \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue examining the cases with leading 9s. The *Stadtwald Zittau* (fdist_id 2691) is a special case among those special cases. From the fdist_id and the maximum year of occurence in the data we can already conclude that it is not in either of the restructured counties. According to Sachsenforst the correct procedure for this fdist_id is to just add the corresponding observations to the forestry district *Zittau* (fdist_id 2601)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate fdist_id 2691 to fdist_id 2601 and add the observations\n",
    "\n",
    "# in column 'fdist_id' change all occurrences of 2691 to 2601\n",
    "infestation_history['fdist_id'] = infestation_history[\n",
    "    'fdist_id'\n",
    "].replace(2691, 2601)\n",
    "\n",
    "# aggregate the values \n",
    "# by summing them together for the 'infested_wood' column\n",
    "# but only if every other column value is the same (same observation)\n",
    "infestation_history['infested_wood'] = infestation_history.groupby(\n",
    "    [\n",
    "        'fdist_id', \n",
    "        'year', \n",
    "        'timeframe', \n",
    "        'forest_ownership'\n",
    "    ]\n",
    ")['infested_wood'].transform('sum')\n",
    "\n",
    "#  do the same for the 'disposed_wood' column\n",
    "infestation_history['disposed_wood'] = infestation_history.groupby(\n",
    "    [\n",
    "        'fdist_id', \n",
    "        'year', \n",
    "        'timeframe', \n",
    "        'forest_ownership'\n",
    "    ]\n",
    ")['disposed_wood'].transform('sum')\n",
    "\n",
    "# now the values are aggregated correctly but duplicated \n",
    "# (since we did't change the shape of the dataframe)\n",
    "# drop the duplicated rows that were just created\n",
    "infestation_history.drop_duplicates(inplace=True)\n",
    "\n",
    "# reset index\n",
    "infestation_history.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Loading and formating forestry district information\n",
    "\n",
    "For the remaining forestry districts we need to distinguish between the old borders and the new ones. Sachsenforst supplied us with two shape files, one with the current district borders for all forestry districts and one with only old borders of districts that changed in some way. The districts in the old shapefile are not yet formated in the same way as our infestation_history dataframe. We have to change the 'fdist_id' numbers for the abolished districts so they match the format with the leading 9s. Currently they still have leading zeros. After that we merge both geodataframes.\n",
    "\n",
    "Every row corresponds to one forestry district. The column names are as follows:\n",
    "* **county_name** - The name of the county this forestry district is located in.\n",
    "* **fdist_name** - The name of the forestry district.\n",
    "* **fdist_id** - Unique identifier for the forestry district. Has four digits. The first two digits are made up of county_nr and the last two are made up of fdist_nr. For the file with the new borders, same as the fdist_id in the infestation_history dataframe. For the file with the old borders, the third digit still has to be changed to a nine to match the fdist_id in the infestation_history dataframe.\n",
    "* **area_nse** - Forest area (in ha) that is not state owned (private/corporate forest) and endangered by the spruce bark beetle. Endangered forest is forest with a spruce ratio > 10% and a tree height >= 20 m.\n",
    "* **area_nsne** - Forest area (in ha) that is not state owned (private/corporate forest) and not endangered by the spruce bark beetle.\n",
    "* **area_se** - Forest area (in ha) that is state owned and endangered by the spruce bark beetle. Endangered forest is forest with a spruce ratio > 10% and a tree height >= 20 m.\n",
    "* **area_sne** - Forest area (in ha) that is state owned (private/corporate forest) and not endangered by the spruce bark beetle.\n",
    "* **geometry** - The forestry district border as polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mittelsachsen</td>\n",
       "      <td>Reinsberg</td>\n",
       "      <td>2203</td>\n",
       "      <td>1597.32</td>\n",
       "      <td>3274.630917</td>\n",
       "      <td>2706.18</td>\n",
       "      <td>2133.910411</td>\n",
       "      <td>POLYGON ((386902.476 5656907.025, 386910.595 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mittelsachsen</td>\n",
       "      <td>Geringswalde</td>\n",
       "      <td>2201</td>\n",
       "      <td>841.61</td>\n",
       "      <td>3508.605810</td>\n",
       "      <td>196.15</td>\n",
       "      <td>1453.972847</td>\n",
       "      <td>POLYGON ((332902.962 5650328.573, 332905.989 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leipzig</td>\n",
       "      <td>Leipziger Land</td>\n",
       "      <td>2902</td>\n",
       "      <td>401.71</td>\n",
       "      <td>8199.853850</td>\n",
       "      <td>615.51</td>\n",
       "      <td>5314.476829</td>\n",
       "      <td>POLYGON ((332897.160 5650325.466, 332893.592 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mittelsachsen</td>\n",
       "      <td>Striegistal</td>\n",
       "      <td>2202</td>\n",
       "      <td>954.18</td>\n",
       "      <td>3156.650864</td>\n",
       "      <td>1147.04</td>\n",
       "      <td>1844.186239</td>\n",
       "      <td>MULTIPOLYGON (((377509.195 5657427.330, 377569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>Süd</td>\n",
       "      <td>2703</td>\n",
       "      <td>392.75</td>\n",
       "      <td>4365.001441</td>\n",
       "      <td>381.91</td>\n",
       "      <td>1973.920712</td>\n",
       "      <td>POLYGON ((377329.166 5657157.286, 377285.838 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_name      fdist_name fdist_id  area_nse    area_nsne  area_se  \\\n",
       "0  Mittelsachsen       Reinsberg     2203   1597.32  3274.630917  2706.18   \n",
       "1  Mittelsachsen    Geringswalde     2201    841.61  3508.605810   196.15   \n",
       "2        Leipzig  Leipziger Land     2902    401.71  8199.853850   615.51   \n",
       "3  Mittelsachsen     Striegistal     2202    954.18  3156.650864  1147.04   \n",
       "4         Meißen             Süd     2703    392.75  4365.001441   381.91   \n",
       "\n",
       "      area_sne                                           geometry  \n",
       "0  2133.910411  POLYGON ((386902.476 5656907.025, 386910.595 5...  \n",
       "1  1453.972847  POLYGON ((332902.962 5650328.573, 332905.989 5...  \n",
       "2  5314.476829  POLYGON ((332897.160 5650325.466, 332893.592 5...  \n",
       "3  1844.186239  MULTIPOLYGON (((377509.195 5657427.330, 377569...  \n",
       "4  1973.920712  POLYGON ((377329.166 5657157.286, 377285.838 5...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the first shape file as a geopandas geodataframe\n",
    "districts_new = gpd.read_file(\n",
    "    r'data_raw/shape/ufb_rev_wald_teil.shp', \n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "# column names\n",
    "districts_new.columns=[\n",
    "    'county_name',\n",
    "    'fdist_name', \n",
    "    'fdist_id', \n",
    "    'area_nse', \n",
    "    'area_nsne', \n",
    "    'area_se', \n",
    "    'area_sne', \n",
    "    'geometry'\n",
    "]\n",
    "\n",
    "# display first few rows of the dataframe\n",
    "districts_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>Nord</td>\n",
       "      <td>2703</td>\n",
       "      <td>143.31</td>\n",
       "      <td>5780.407594</td>\n",
       "      <td>1.09</td>\n",
       "      <td>768.093453</td>\n",
       "      <td>POLYGON ((418952.942 5692288.782, 418909.147 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>West</td>\n",
       "      <td>2701</td>\n",
       "      <td>22.80</td>\n",
       "      <td>4255.041515</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3650.063576</td>\n",
       "      <td>POLYGON ((389635.997 5699901.234, 389648.747 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>Süd</td>\n",
       "      <td>2702</td>\n",
       "      <td>411.13</td>\n",
       "      <td>4543.837549</td>\n",
       "      <td>381.83</td>\n",
       "      <td>1975.417673</td>\n",
       "      <td>POLYGON ((378695.051 5678837.912, 378676.082 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erzgebirgskreis</td>\n",
       "      <td>Annaberg</td>\n",
       "      <td>2105</td>\n",
       "      <td>2408.13</td>\n",
       "      <td>1882.699804</td>\n",
       "      <td>6142.78</td>\n",
       "      <td>2810.089861</td>\n",
       "      <td>MULTIPOLYGON (((366499.454 5606840.063, 366468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erzgebirgskreis</td>\n",
       "      <td>Eibenstock</td>\n",
       "      <td>2101</td>\n",
       "      <td>726.57</td>\n",
       "      <td>1754.566081</td>\n",
       "      <td>10922.47</td>\n",
       "      <td>3573.808856</td>\n",
       "      <td>POLYGON ((333355.788 5609845.954, 333373.979 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county_name  fdist_name fdist_id  area_nse    area_nsne   area_se  \\\n",
       "0           Meißen        Nord     2703    143.31  5780.407594      1.09   \n",
       "1           Meißen        West     2701     22.80  4255.041515      3.93   \n",
       "2           Meißen         Süd     2702    411.13  4543.837549    381.83   \n",
       "3  Erzgebirgskreis    Annaberg     2105   2408.13  1882.699804   6142.78   \n",
       "4  Erzgebirgskreis  Eibenstock     2101    726.57  1754.566081  10922.47   \n",
       "\n",
       "      area_sne                                           geometry  \n",
       "0   768.093453  POLYGON ((418952.942 5692288.782, 418909.147 5...  \n",
       "1  3650.063576  POLYGON ((389635.997 5699901.234, 389648.747 5...  \n",
       "2  1975.417673  POLYGON ((378695.051 5678837.912, 378676.082 5...  \n",
       "3  2810.089861  MULTIPOLYGON (((366499.454 5606840.063, 366468...  \n",
       "4  3573.808856  POLYGON ((333355.788 5609845.954, 333373.979 5...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the second shape file as a geopandas geodataframe\n",
    "districts_old = gpd.read_file(\n",
    "    r'data_raw/shape/ufb_rev_vorUmstrukturierungen.shp', \n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "# column names\n",
    "districts_old.columns=[\n",
    "    'county_name', \n",
    "    'fdist_name', \n",
    "    'fdist_id', \n",
    "    'area_nse', \n",
    "    'area_nsne', \n",
    "    'area_se', \n",
    "    'area_sne', \n",
    "    'geometry'\n",
    "]\n",
    "# display first few rows of the dataframe\n",
    "districts_old.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the districts_old geodataframe so it matches the notation in the infestation_history dataframe. This is done by changing the third digit from a zero to a nine. We also change the fdist_id in both geodataframes from a string to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the leading 9 notation for abolished forestry districts\n",
    "# add 90 to every 'fdist_id' in the districts_old dataframe \n",
    "districts_old['fdist_id'] = districts_old['fdist_id'].astype(int) + 90\n",
    "\n",
    "# also change 'fdist_id' of districts_new to type int\n",
    "districts_new['fdist_id'] = districts_new['fdist_id'].astype(int)\n",
    "\n",
    "# merge the geodataframes\n",
    "districts = pd.merge(districts_new, districts_old, how ='outer') \n",
    "\n",
    "# shape should be 64x8 now (53 new districts + 11 old districts)\n",
    "districts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make one more modification and the change some forestry district names slightly, to make them unambiguous. Currently, the counties *Meißen* and *Zwickau* have their districts labeled as *Nord* (north), *Süd* (south) etc. Since we also have the 'county_name' column to distinguish them, this is currently not a dealbreaker, but we would need to consult the county_name column every time to distinguish forestry district names. This is tedious, we'd rather just use the district names by themself. Thus we add the first county name letter to the name ('M Nord', 'Z Nord' and so on) for those forestry districts only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Süd</td>\n",
       "      <td>2703</td>\n",
       "      <td>392.75</td>\n",
       "      <td>4365.001441</td>\n",
       "      <td>381.91</td>\n",
       "      <td>1973.920712</td>\n",
       "      <td>POLYGON ((377329.166 5657157.286, 377285.838 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zwickau</td>\n",
       "      <td>Z Nord</td>\n",
       "      <td>2401</td>\n",
       "      <td>1319.45</td>\n",
       "      <td>4145.980567</td>\n",
       "      <td>1348.61</td>\n",
       "      <td>1555.580286</td>\n",
       "      <td>POLYGON ((305774.813 5632213.129, 305790.058 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>2704</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>MULTIPOLYGON (((378097.915 5695126.311, 378079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Zwickau</td>\n",
       "      <td>Z Süd</td>\n",
       "      <td>2402</td>\n",
       "      <td>1794.78</td>\n",
       "      <td>6175.259947</td>\n",
       "      <td>196.48</td>\n",
       "      <td>236.623276</td>\n",
       "      <td>POLYGON ((324855.422 5602320.960, 324853.742 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Ost</td>\n",
       "      <td>2702</td>\n",
       "      <td>114.56</td>\n",
       "      <td>4945.945638</td>\n",
       "      <td>0.60</td>\n",
       "      <td>762.365790</td>\n",
       "      <td>POLYGON ((413698.678 5674573.351, 413686.981 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Nord</td>\n",
       "      <td>2701</td>\n",
       "      <td>33.41</td>\n",
       "      <td>3794.019452</td>\n",
       "      <td>3.85</td>\n",
       "      <td>243.218414</td>\n",
       "      <td>POLYGON ((408736.142 5692125.831, 408767.450 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Nord</td>\n",
       "      <td>2793</td>\n",
       "      <td>143.31</td>\n",
       "      <td>5780.407594</td>\n",
       "      <td>1.09</td>\n",
       "      <td>768.093453</td>\n",
       "      <td>POLYGON ((418952.942 5692288.782, 418909.147 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>2791</td>\n",
       "      <td>22.80</td>\n",
       "      <td>4255.041515</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3650.063576</td>\n",
       "      <td>POLYGON ((389635.997 5699901.234, 389648.747 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Meißen</td>\n",
       "      <td>M Süd</td>\n",
       "      <td>2792</td>\n",
       "      <td>411.13</td>\n",
       "      <td>4543.837549</td>\n",
       "      <td>381.83</td>\n",
       "      <td>1975.417673</td>\n",
       "      <td>POLYGON ((378695.051 5678837.912, 378676.082 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county_name fdist_name  fdist_id  area_nse    area_nsne  area_se  \\\n",
       "4       Meißen      M Süd      2703    392.75  4365.001441   381.91   \n",
       "9      Zwickau     Z Nord      2401   1319.45  4145.980567  1348.61   \n",
       "14      Meißen     M West      2704     36.08  1499.801018     0.08   \n",
       "27     Zwickau      Z Süd      2402   1794.78  6175.259947   196.48   \n",
       "31      Meißen      M Ost      2702    114.56  4945.945638     0.60   \n",
       "36      Meißen     M Nord      2701     33.41  3794.019452     3.85   \n",
       "53      Meißen     M Nord      2793    143.31  5780.407594     1.09   \n",
       "54      Meißen     M West      2791     22.80  4255.041515     3.93   \n",
       "55      Meißen      M Süd      2792    411.13  4543.837549   381.83   \n",
       "\n",
       "       area_sne                                           geometry  \n",
       "4   1973.920712  POLYGON ((377329.166 5657157.286, 377285.838 5...  \n",
       "9   1555.580286  POLYGON ((305774.813 5632213.129, 305790.058 5...  \n",
       "14  3411.198775  MULTIPOLYGON (((378097.915 5695126.311, 378079...  \n",
       "27   236.623276  POLYGON ((324855.422 5602320.960, 324853.742 5...  \n",
       "31   762.365790  POLYGON ((413698.678 5674573.351, 413686.981 5...  \n",
       "36   243.218414  POLYGON ((408736.142 5692125.831, 408767.450 5...  \n",
       "53   768.093453  POLYGON ((418952.942 5692288.782, 418909.147 5...  \n",
       "54  3650.063576  POLYGON ((389635.997 5699901.234, 389648.747 5...  \n",
       "55  1975.417673  POLYGON ((378695.051 5678837.912, 378676.082 5...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate the fdist_name column for all foretry districts in Zwickau\n",
    "# and add the letter Z to the start of the string\n",
    "districts.loc[\n",
    "    districts['county_name'] == 'Zwickau', \n",
    "    'fdist_name'\n",
    "] = districts.loc[\n",
    "    districts['county_name'] == 'Zwickau', \n",
    "    'fdist_name'\n",
    "].map(\n",
    "    lambda x: 'Z '+ x\n",
    ")\n",
    "\n",
    "# locate the fdist_name column for all foretry districts in Meißen\n",
    "# and add the letter M to the start of the string\n",
    "districts.loc[\n",
    "    districts['county_name'] == 'Meißen', \n",
    "    'fdist_name'\n",
    "] = districts.loc[\n",
    "    districts['county_name'] == 'Meißen', \n",
    "    'fdist_name'\n",
    "].map(\n",
    "    lambda x: 'M '+ x\n",
    ")\n",
    "\n",
    "# check the results by filtering for Meißen, Zwickau\n",
    "districts[districts['county_name'].isin(['Meißen', 'Zwickau'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old and new district borders are now correctly labeled in a single geodataframe and match the fdist_id in the infestation_history dataframe. \n",
    "\n",
    "## 3.3 Supplement forestry district features\n",
    "\n",
    "From the columns in our districts geodataframe we can derive additional features. First we calculate the actual area of all districts as well as the endangered forest density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area for Kreisfreie Stadt Leipzig is 297.8 km^2, should be 297.8 km^2\n"
     ]
    }
   ],
   "source": [
    "# calculate area of the forestry district polygons in square kilometeres\n",
    "# to get the correct area, we need to use an equal area projection \n",
    "# (in this case cea) \n",
    "districts['area_fdist'] = districts.to_crs(\n",
    "    {'proj':'cea'}\n",
    ")['geometry'].area / 1000000\n",
    "\n",
    "# as a brief evaluation we check the area for the town of Leipzig \n",
    "# area should be 297.8 km^2 according to wikipedia\n",
    "kfs_leipzig_area = districts[\n",
    "    districts['county_name'] == 'Kreisfreie Stadt Leipzig'\n",
    "]['area_fdist'].sum()\n",
    "\n",
    "print(f'Area for Kreisfreie Stadt Leipzig is {kfs_leipzig_area:.1f} km^2,',\n",
    "      'should be 297.8 km^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the endangered forest density is the area \n",
    "# of non state and state endangered forest (in km^2)\n",
    "# divided by the total forestry district area\n",
    "districts['endangered_forest_density'] = (\n",
    "    districts['area_nse'] + districts['area_se']\n",
    ") * 100 / districts['area_fdist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to use the geographical information contained within the geodataframe in our model, we calculate the centroid x and y coordinates of the polygons. Thus, we get two numerical features with location information of the districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for coordinates of centroid for every district\n",
    "# could be used as features instead of dummy for every district\n",
    "districts['centroid_xcoord'] = districts[\n",
    "    'geometry'\n",
    "].map(\n",
    "    lambda x: x.centroid.coords[0][0]\n",
    ")\n",
    "\n",
    "districts['centroid_ycoord'] = districts[\n",
    "    'geometry'\n",
    "].map(\n",
    "    lambda x: x.centroid.coords[0][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Insert missing observations in infestation history\n",
    "\n",
    "Before we merge the infestation history with the information on forestry districts, we need to pad the observations in the infestation_history dataframe. The dataset currently does not include an observation for every combination of forestry district, forest ownership and observation periods. The cause of these missing observations is that sometimes neither damaged nor disposed wood is reported. This may be the case if a forestry district does have almost no endangered forest (of the respective forest ownership type), a winter month yielded unfavorable conditions for bark beetles or the infestation subsided locally in a particular year (or a combination of these factors). According to *Sachsenforst* the appropriate procedure is to assume that for every observation not in the dataframe there was neither infested not disposed wood, because none was reported. Since this is still crucial information, we augment the dataset so that these cases are taken into account.\n",
    "\n",
    "Let's see how many rows our dataset currently has in total and how many of those rows already have neither infested nor disposed wood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially 839 observations with neither infested wood nor disposed wood (out of 8007 toal observations).\n"
     ]
    }
   ],
   "source": [
    "# how many 'zero rows' do we already have?\n",
    "n_zrows = infestation_history[\n",
    "    (infestation_history['infested_wood'] == 0) & \n",
    "    (infestation_history['disposed_wood'] == 0)\n",
    "].shape[0]\n",
    "\n",
    "print(f'Initially {n_zrows} observations with neither infested wood nor',\n",
    "      f'disposed wood (out of {infestation_history.shape[0]}',\n",
    "      f'toal observations).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in total we have 8007 observations. If we had every combination of timeframe, district and forest ownership for the years 2006 until February 2020 in the dataset, we would have 12,637 observations. We will also add the year 2005 in the dataframe, since we have the climate data for this year availabe. In case we ever want to use a moving average as a feature, we can already start with valid values for 2006. This makes the total rows we should have at the end of this chapter 13485. Calculations below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after padding should be 12636 (13484 including 2005).\n"
     ]
    }
   ],
   "source": [
    "# estimate how many rows we should get after filling in zero rows\n",
    "\n",
    "# 2006 - September 2020 (without 2005)\n",
    "# 12 full years with 8 timeframes and 53 forestry districts\n",
    "# (these years are 2006-2012 and 2015-2019 = 12 total)\n",
    "# 12 remaining timeframes with 53 districts (Jan-May 2013 & Jan-Sep 2020)\n",
    "# 11 timeframes with 54 forestry districts (Jul 2013 - Sep 2014)\n",
    "# everything x2 for state & non-state forest\n",
    "\n",
    "n_full = (\n",
    "    (12 * 8 * 53) + \n",
    "    (1 * 12 * 53) + \n",
    "    (1 * 11 * 54)\n",
    ") * 2\n",
    "\n",
    "# 2005 - September 2020 (including 2005 for climate data only)\n",
    "# same as above, only one more full year\n",
    "n_full_2005 = (\n",
    "    (13 * 8 * 53) + \n",
    "    (1 * 12 * 53) + \n",
    "    (1 * 11 * 54) \n",
    ") * 2\n",
    "\n",
    "print(f'Total rows after padding should be {n_full}',\n",
    "      f'({n_full_2005} including 2005).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated in the above calculation, accounting for the exact forestry district borders of every year and timeframe is somewhat complicated, but still neccessary to yield reliable results. Before we fill the dataset with missing rows, we construct one dataframe for each combination of forestry districts that existed from 2006 untill 2020. They are created from subsets of our districts_old and districts_new geodataframes. In July 2013 all districts of the *Meißen* county changed from their xx9x version to the xx0x version. In September 2014 the forestry districts of the *Erzgebirgskreis* county followed suit. So in total we have three different geographical borders, one before July 2013 (all old borders for *Meißen* and *Erzgebirgskreis*), one after September 2014 (all new borders) and one in between (*Meißen* had new borders already, *Erzgebirgskreis* still had the old ones).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for the different forestry district border changes\n",
    "# by making three geodataframes containing the right polygons\n",
    "\n",
    "# before July 2013: all old borders for Meißen and Erzgebirgskreis\n",
    "# other borders are unchanged and thus in districts_new\n",
    "districts_before_jul2013 = pd.concat(\n",
    "    [\n",
    "        districts_old, \n",
    "        districts_new[\n",
    "            (districts_new['county_name'] != 'Erzgebirgskreis') & \n",
    "            (districts_new['county_name'] != 'Meißen')\n",
    "        ]\n",
    "    ], axis=0)\n",
    "\n",
    "# bewtween July 2013 and September 2014\n",
    "# take Erzgebirgskreis from districts_old \n",
    "# and everything else from districts_new\n",
    "districts_jul2013_sep2014 = pd.concat(\n",
    "    [\n",
    "        districts_old[\n",
    "            districts_old['county_name'] == 'Erzgebirgskreis'\n",
    "        ], \n",
    "        districts_new[\n",
    "            districts_new['county_name'] != 'Erzgebirgskreis'\n",
    "        ]\n",
    "    ], axis=0)\n",
    "\n",
    "# the districts after September 2014 are already in districts_new\n",
    "districts_after_sep2014 = districts_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally fill in the missing rows for every observation with zeroes for infested and disposed wood. The first part is to define a function which creates a row based on its input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_row(df, fdist_id, year, timeframe, forest_ownership):\n",
    "    '''\n",
    "    This function takes in a dataframe, as well as values for the columns\n",
    "    'fdist_id', 'year', 'timeframe' and 'forest_ownership' of this \n",
    "    dataframe. \n",
    "    It returns a dictionary with a new row where the last two column \n",
    "    values are zero, only if there is not yet a row with the \n",
    "    other column values as specified by the inputs.\n",
    "    \n",
    "    inputs:\n",
    "        - df: the dataframe in question\n",
    "        - district: value for the 'fdist_id' column\n",
    "        - year: value for the 'year' column\n",
    "        - timeframe: value for the 'timeframe' column\n",
    "        - forest_ownership: value for the forest_ownership column\n",
    "        \n",
    "    returns:\n",
    "        - a dictionary serving as the new row in the dataframe, if the\n",
    "          row in question does not exist yet\n",
    "    '''\n",
    "    \n",
    "    # first check if there already is an observation for \n",
    "    # this combination of parameters    \n",
    "    if not (\n",
    "        (df['fdist_id'] == fdist_id) & \n",
    "        (df['year'] == year) &\n",
    "        (df['timeframe'] == timeframe) &\n",
    "        (df['forest_ownership'] == forest_ownership)\n",
    "    ).any():\n",
    "        \n",
    "        # if there is no observation yet: create one with the last two \n",
    "        # columns as zero\n",
    "        # note: this will only work if the shape and column names \n",
    "        # are exactly as they are in infestation_history\n",
    "        # however we do it this way because the function can also be used\n",
    "        # for demolition wood this way (more on that later)\n",
    "        return {\n",
    "            'fdist_id': fdist_id, \n",
    "            'year': year,\n",
    "            'timeframe': timeframe,\n",
    "            'forest_ownership': forest_ownership,\n",
    "            df.columns[-2]: 0,\n",
    "            df.columns[-1]: 0\n",
    "        } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part is to go over all possible combination of features and call the create_zero_row() function. This is done in the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_fill(df=infestation_history, \n",
    "              districts_before_jul2013=districts_before_jul2013, \n",
    "              districts_jul2013_sep2014=districts_jul2013_sep2014, \n",
    "              districts_after_sep2014=districts_after_sep2014):\n",
    "    '''\n",
    "    This function takes in a dataframe and iterates over all possible\n",
    "    combinations of years, timeframes, forestry districts \n",
    "    and forest ownerships. \n",
    "    It then calls the create_zero_row function with the appicable inputs.\n",
    "    \n",
    "    inputs:\n",
    "        - df: the dataframe in question\n",
    "        - districts_before_jul2013: a geodataframe with information\n",
    "          on the forestry districts that existed before July 2013\n",
    "        - districts_jul2013_sep2014: a geodataframe with information\n",
    "          on the forestry districts that existed between July 2013\n",
    "          and September 2014\n",
    "        - districts_after_sep2014: a geodataframe with information\n",
    "          on the forestry districts that existed after September 2014\n",
    "    returns:\n",
    "        - the augemnted dataframe, filled with new rows whenever a valid \n",
    "          combination of features did not exist in df. infested_wood and \n",
    "          disposed_wood values are zero in those rows\n",
    "    '''\n",
    "    \n",
    "    # print current number of rows in df\n",
    "    print(f'Number of rows before zero_fill(): {df.shape[0]}')\n",
    "    \n",
    "    # to check every valid combination of timeframes, forest types, years \n",
    "    # and districts we use nested for loops\n",
    "    # loop through all unique months and quarters\n",
    "    for tf in df['timeframe'].unique():\n",
    "        \n",
    "        # loop through forest ownership types\n",
    "        for fo in df['forest_ownership'].unique():\n",
    "            \n",
    "            # loop through all years we want to include\n",
    "            for yr in range(2005, 2021):\n",
    "                \n",
    "                # depending on the year there were differences\n",
    "                # in forestry districts\n",
    "                # we check which year it is via an if-statement\n",
    "                \n",
    "                # before July 2013\n",
    "                if yr < 2013 or (\n",
    "                    yr == 2013 and \n",
    "                    tf in ['01 Januar-März', '04 April', \n",
    "                           '05 Mai', '06 Juni']\n",
    "                ):\n",
    "                    \n",
    "                    # loop only through the old districts before July 2013\n",
    "                    for fd in districts_before_jul2013[\n",
    "                        'fdist_id'\n",
    "                    ].unique():\n",
    "                    \n",
    "                        # create new row if conditions are met \n",
    "                        # by calling create_zero_rows()\n",
    "                        df = df.append(\n",
    "                            create_zero_row(df, fd, yr, tf, fo), \n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                        \n",
    "                # between July 2013 and September 2014    \n",
    "                elif yr == 2013 or (\n",
    "                    yr == 2014 and not \n",
    "                    tf == '10 Oktober-Dezember'\n",
    "                ):\n",
    "                    \n",
    "                    # loop only through the districts from July 2013 \n",
    "                    # until December 2014\n",
    "                    for fd in districts_jul2013_sep2014[\n",
    "                        'fdist_id'\n",
    "                    ].unique():\n",
    "                    \n",
    "                        # create new row if conditions are met \n",
    "                        # by calling create_zero_rows()\n",
    "                        df = df.append(\n",
    "                            create_zero_row(df, fd,yr, tf, fo),\n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                        \n",
    "                # after September 2014        \n",
    "                elif yr >= 2014 and not (\n",
    "                    yr == 2020 and \n",
    "                    tf == '10 Oktober-Dezember'\n",
    "                ):\n",
    "                    \n",
    "                    # loop only through the new districts after 2014\n",
    "                    for fd in districts_after_sep2014[\n",
    "                        'fdist_id'\n",
    "                    ].unique():\n",
    "                        \n",
    "                        # create new row if conditions are met \n",
    "                        # by calling create_zero_rows()\n",
    "                        df = df.append(\n",
    "                            create_zero_row(df, fd, yr, tf, fo), \n",
    "                            ignore_index=True\n",
    "                        )\n",
    "                        \n",
    "    # reset the index\n",
    "    df.reset_index(inplace=True, drop=True)  \n",
    "    \n",
    "    # print new number of rows\n",
    "    print(f'Number of rows after zero_fill(): {df.shape[0]}')\n",
    "          \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before zero_fill(): 8007\n",
      "Number of rows after zero_fill(): 13484\n"
     ]
    }
   ],
   "source": [
    " # call zero_fill() function to augment infestation_history\n",
    "infestation_history = zero_fill(infestation_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows after inserting missing obervations matches what we calculated earlier. Now that we finally have all observations we'll ever need, we can focus on creating new features and integrating our other data sources in the infestation_history dataframe. First, we merge the info from the districts geodataframe with infestation_history. To merge, we use the fdist_id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge information on the forestry districts \n",
    "# with the obersvations in infestation_history\n",
    "infestation_history = pd.merge(\n",
    "    infestation_history, \n",
    "    districts[[\n",
    "        'county_name', \n",
    "        'fdist_name',\n",
    "        'area_nse', \n",
    "        'area_nsne', \n",
    "        'area_se', \n",
    "        'area_sne', \n",
    "        'fdist_id', \n",
    "        'centroid_xcoord', \n",
    "        'centroid_ycoord', \n",
    "        'area_fdist', \n",
    "        'endangered_forest_density'\n",
    "    ]], \n",
    "    on='fdist_id')\n",
    "\n",
    "# we also save the districts geodataframe as a shape file \n",
    "# this way we can access it during the EDA\n",
    "# \n",
    "# appending the geometry feature to our main dataset\n",
    "# would unnecessarily impair performance,memory and storage \n",
    "# as the information contained in the polygons are rather large\n",
    "districts.to_file('forestry_districts.shp', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Meteorological raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every meteorological parameter and every month (alternatively day), we have one raster file with a 1000 m x 1000 m raster that covers all of Saxony. Before the aggregation of the climate data takes place, we define two functions to help us in our endevour. The first one reads in a specific raster file and calculates the mean for all polygon geometries that we pass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_mean(filename, polygons):\n",
    "    '''\n",
    "    This function calculates the mean of values in a raster grid for \n",
    "    specific polygon shapes. \n",
    "    This is done by masking the raster grid with the polygon vectors and \n",
    "    using the masked raster points to calculate the mean.\n",
    "\n",
    "    inputs:\n",
    "        - filename: path/filename of the raster file\n",
    "        - polygons: a list of polygons that we want to calculate mean values for\n",
    "        \n",
    "    returns:\n",
    "        - a list with one element for every input polygon, every element being the\n",
    "          mean value of the raster masked with the polygon\n",
    "    '''  \n",
    "    # try to read in raster file\n",
    "    try:\n",
    "        current_raster = rasterio.open(filename, nodata=-9999.0)\n",
    "        \n",
    "    # specify procedure when file does not exist\n",
    "    except: \n",
    "        # return NaN for all polygons and print message with filename\n",
    "        print(f'File {filename} not found in directory. Returning NaN.')\n",
    "        return [np.nan for i in range(polygons.shape[0])] \n",
    "    \n",
    "    # prepare list with results\n",
    "    results = []\n",
    "    \n",
    "    # do masking and calculation for every polygon\n",
    "    for polygon in polygons['geometry']:\n",
    "        \n",
    "        # mask raster with polygon and read in the relevant raster points\n",
    "        masked, mask_transform = mask(\n",
    "            dataset=current_raster, \n",
    "            shapes=[polygon], \n",
    "            crop=True, # avoids loading in the whole raster\n",
    "            filled=False, # mask outside values with nodata instead of 0, \n",
    "                          # so we can safely compute zonal stats\n",
    "            all_touched=True # overfill polygon instead of underfilling\n",
    "        ) \n",
    "        \n",
    "        # calculate the mean of the remaining raster points\n",
    "        # use numpy.ma as it supports masked arrays\n",
    "        # and append to results\n",
    "        results.append(\n",
    "            np.ma.mean(masked)\n",
    "        )\n",
    "        \n",
    "    # return results list\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function fixes a problem that stems from the fact we have different timeframe lengths. The observations are gathered monthly from April until September and quarterly for the other six months. Some climate parameterts are formulated as the sum of daily values. For example the sunshine duration 'SD0' of a month is the sum of sunshine durations of every day. Our target variable is the infested wood that was **accrued** in the timeframe, meaning it is the sum of the accrued wood for every month (technically also each day or other arbitrary period). Thus, for these quarterly timeframes we want the features in question to also be added together (for example total sunshine duration of those three months, so we can explore the relationship between sunshine duration and target variable).\n",
    "\n",
    "In case one of the files does not exist in the data (for now every file does exist, might not be the caser in production), the coorect approach would be to caluclate the numpy.nansum. However in case all of the three files for the qurterly values are missing, we want to return NaN, which is not the behavior of numpy.nansum. This why we create a wrapper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nansumwrapper(a, **kwargs):\n",
    "    '''\n",
    "    A function that returns NaN when all elements of an array-like\n",
    "    are NaN and else calculates the nansum of this array-like.\n",
    "    \n",
    "    inputs:\n",
    "        - a: any array-like\n",
    "    returns:\n",
    "        - np.nan if all elements are np.nan, else the nansum of input\n",
    "    '''\n",
    "    if np.isnan(a).all():\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nansum(a, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the aggregation of the climate data. Since reading in thousands of raster files, overlaying vector data and doing calculations with the results is computationally expensive, we do the aggregation in way that we have to read in every file only once, do the necessary calculations and only in the end merge the results onto our main dataset. We also do not want to repeatedly append datatframes (or actually handle dataframes at all) like we did during the insertion of missing rows, where it was really an issue. \n",
    "\n",
    "Because of those reasons we do not iterate over the infestation_history dataframe nor do we use dataframes to append our interim results. As long as we calcualte the meteorological feature values we are working with a list of lists, each inner list representing one of the parameters. Only in the end, after we are done with the aggregation, we transform our results into a pandas dataframe.\n",
    "\n",
    "The following parameters exist in the data, calculated for every month. All parameters will be included as a feature with the same column name in the dataframe:\n",
    "* **TX0** - mean of the daily maximum temperatures in °C\n",
    "* **TM0** - mean temperature in °C\n",
    "* **TN0** - mean of the daily minimum temperatures in °C\n",
    "* **RF0** - mean relative humidity in %\n",
    "* **SD0** - total sunshinde duration in h\n",
    "* **RRU** - total precipitation in mm\n",
    "* **RRK** - corrected total precipitation in mm (corrects systematic errors of the measuring device and installation location such as wetting/evaporation losses)\n",
    "* **FF1** - mean of the daily mean wind velocity 10 metres above ground in m*s-1\n",
    "* **FF2** - mean of the daily mean wind velocity 2 metres above ground in m*s-1\n",
    "* **FFB** - mean of the daily wind speed of the day on the beaufort scale in bft\n",
    "* **RGK** - total global irridiation in kWh*m-2\n",
    "* **ETP** - potential evaporation in mm\n",
    "* **GRV** - potential evapotranspiration in mm\n",
    "* **KWU** - waterbalance in mm\n",
    "* **KWK** - corrected waterbalance in mm (corrects systematic errors of the measuring device and installation location such as wetting/evaporation losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 2005, elapsed time: 0.00 min\n",
      "Starting with 2006, elapsed time: 1.67 min\n",
      "Starting with 2007, elapsed time: 3.54 min\n",
      "Starting with 2008, elapsed time: 5.48 min\n",
      "Starting with 2009, elapsed time: 7.45 min\n",
      "Starting with 2010, elapsed time: 9.41 min\n",
      "Starting with 2011, elapsed time: 11.38 min\n",
      "Starting with 2012, elapsed time: 13.27 min\n",
      "Starting with 2013, elapsed time: 15.25 min\n",
      "Starting with 2014, elapsed time: 17.15 min\n",
      "Starting with 2015, elapsed time: 18.85 min\n",
      "Starting with 2016, elapsed time: 20.29 min\n",
      "Starting with 2017, elapsed time: 21.68 min\n",
      "Starting with 2018, elapsed time: 23.08 min\n",
      "Starting with 2019, elapsed time: 24.44 min\n",
      "Starting with 2020, elapsed time: 25.80 min\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200300_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200400_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200500_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200600_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200700_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200800_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20200900_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TX0_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TM0_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_TN0_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RF0_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_SD0_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRU_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RRK_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF1_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FF2_MW_20201200_utm.asc not found in directory. Returning NaN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yannic\\.conda\\envs\\python377\\lib\\site-packages\\ipykernel_launcher.py:88: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_FFB_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_RGK_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_ETP_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_GRV_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWU_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20201000_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20201100_utm.asc not found in directory. Returning NaN.\n",
      "File data_raw/climate_monthly_1000/GRID_1_Messungen_Tageswerte_2020_KWK_MW_20201200_utm.asc not found in directory. Returning NaN.\n",
      "Finished aggregation, total time: 26.03 min\n"
     ]
    }
   ],
   "source": [
    "# aggregate meteorological data\n",
    "\n",
    "# specify location of raster files\n",
    "raster_dir = r'data_raw/climate_monthly_1000/'\n",
    "\n",
    "# the obervations from april until september are gathered monthly \n",
    "# while they are gathered quarterly from october till march\n",
    "# create a dictionary that maps the timeframe values from infestation_history \n",
    "# to the naming pattern that is used in the raster file names \n",
    "timeframe_dict = {\n",
    "'01 Januar-März': ['01', '02', '03'],\n",
    "'04 April': ['04'],\n",
    "'05 Mai': ['05'],\n",
    "'06 Juni': ['06'],\n",
    "'07 Juli': ['07'],\n",
    "'08 August': ['08'],\n",
    "'09 September': ['09'],\n",
    "'10 Oktober-Dezember': ['10', '11', '12']\n",
    "}\n",
    "\n",
    "# create a dictionary of all meteorological parameter shorthands to calculate\n",
    "# these shorthands match the notation used in the respective filenames\n",
    "#\n",
    "# they are mapped to the respective aggregation function that will be used \n",
    "# if there are multiple months in the timeframe\n",
    "parameter_info = {\n",
    "    'TX0' : np.nanmean,  \n",
    "    'TM0' : np.nanmean,  \n",
    "    'TN0' : np.nanmean,  \n",
    "    'RF0' : np.nanmean,  \n",
    "    'SD0' : nansumwrapper,\n",
    "    'RRU' : nansumwrapper,\n",
    "    'RRK' : nansumwrapper,\n",
    "    'FF1' : np.nanmean,  \n",
    "    'FF2' : np.nanmean,  \n",
    "    'FFB' : np.nanmean,  \n",
    "    'RGK' : nansumwrapper,\n",
    "    'ETP' : nansumwrapper,\n",
    "    'GRV' : nansumwrapper,\n",
    "    'KWU' : nansumwrapper,\n",
    "    'KWK' : nansumwrapper\n",
    "}\n",
    "\n",
    "# since this might take a while we track the time\n",
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "# use list of lists to store results\n",
    "# one inner list for every parameter plus one containing\n",
    "# the information we use to merge infestation_history on\n",
    "climate_res = [[] for _ in range(len(parameter_info) + 1)]\n",
    "\n",
    "# to read every file only once, iterate over the years (and timeframes) \n",
    "for current_year in np.sort(infestation_history['year'].unique()):\n",
    "\n",
    "    # whenever we start a new year, print elapsed time\n",
    "    elapsed = (time.time() - start) / 60\n",
    "    print(f'Starting with {current_year}, elapsed time: {elapsed:.2f} min')\n",
    "    \n",
    "    # if we are past 2014 we only need to go through the new districts\n",
    "    # else go through all forestry districts in the districts geodataframe\n",
    "    current_districts = districts if current_year <= 2014 else districts_new\n",
    "    \n",
    "    # get the forestry district id as well as the polygons\n",
    "    polygons = current_districts[['fdist_id', 'geometry']]\n",
    "    \n",
    "    # iterate over the timeframes\n",
    "    for current_timeframe in timeframe_dict:\n",
    "        for idx, current_parameter in enumerate(parameter_info):\n",
    "            \n",
    "            # get all filenames \n",
    "            # (one if timeframe is one month, else list has three filenames)\n",
    "            filenames = [\n",
    "                fr'{raster_dir}GRID_1_Messungen_Tageswerte_2020_' +\n",
    "                fr'{current_parameter}_MW_{current_year}' +\n",
    "                fr'{current_month}00_utm.asc' \n",
    "                for current_month in timeframe_dict.get(current_timeframe)\n",
    "            ]\n",
    "            \n",
    "            # call raster_mean() function we defined earlier\n",
    "            aggregation_results = [\n",
    "                raster_mean(filename, polygons) for filename in filenames\n",
    "            ]\n",
    "            \n",
    "            # now use mapped function to handle timeframes \n",
    "            # with multiple months\n",
    "            results_after_dispatch = [\n",
    "                parameter_info[current_parameter](x) for x in zip(\n",
    "                    *aggregation_results\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            # now we have one list left independent of timeframe\n",
    "            # extend results\n",
    "            climate_res[idx].extend(results_after_dispatch)         \n",
    "        \n",
    "        # extend the list on which we merge the results by specifying what \n",
    "        # combination of year, timeframe and districts we calculated\n",
    "        merge_dummies = [\n",
    "            f'{current_year}-{current_timeframe}-{dist}' \n",
    "            for dist in polygons['fdist_id']\n",
    "        ]\n",
    "        climate_res[-1].extend(merge_dummies)\n",
    "\n",
    "\n",
    "\n",
    "# calculation done for all years, timeframes, districts and parameters\n",
    "# transform results into dataframe\n",
    "climate_res = pd.DataFrame(climate_res).T\n",
    "\n",
    "# name columns correctly\n",
    "climate_res.columns = [*parameter_info, 'merge_dummy']\n",
    "\n",
    "# print final time\n",
    "print(f'Finished aggregation, total time: {(time.time()-start)/60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with year 2005, elapsed time: 0.0 min\n",
      "Starting with year 2006, elapsed time: 3.01 min\n",
      "Starting with year 2007, elapsed time: 6.02 min\n",
      "Starting with year 2008, elapsed time: 9.04 min\n",
      "Starting with year 2009, elapsed time: 12.07 min\n",
      "Starting with year 2010, elapsed time: 15.11 min\n",
      "Starting with year 2011, elapsed time: 18.17 min\n",
      "Starting with year 2012, elapsed time: 21.21 min\n",
      "Starting with year 2013, elapsed time: 24.25 min\n",
      "Starting with year 2014, elapsed time: 28.65 min\n",
      "Starting with year 2015, elapsed time: 40.19 min\n",
      "Starting with year 2016, elapsed time: 44.61 min\n",
      "Starting with year 2017, elapsed time: 55.27 min\n",
      "Starting with year 2018, elapsed time: 60.76 min\n",
      "Starting with year 2019, elapsed time: 64.78 min\n",
      "Starting with year 2020, elapsed time: 67.52 min\n",
      "Finished heatsum calculations, total time: 68.08 min\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# specify location of raster files\n",
    "raster_dir=r'data_raw/climate/'\n",
    "\n",
    "# since this will take a while we track the time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# we do not want to append to dataframes and thus use a list of lists \n",
    "# (one list for every parameter and a final list that will be used for merging)\n",
    "heatsum_res = [[],[],[]]\n",
    "\n",
    "\n",
    "for current_year in np.sort(infestation_history['year'].unique()):\n",
    "    \n",
    "    elapsed_time = round((time.time() - start_time)/60, 2)\n",
    "    print(f'Starting with year {current_year}, elapsed time: {elapsed_time} min')\n",
    "    \n",
    "    polygons = districts[['fdist_id', 'geometry']] if current_year <= 2014 else districts_new[['fdist_id', 'geometry']]\n",
    "    \n",
    "    for current_timeframe in timeframe_dict:\n",
    "        \n",
    "        filenames = []\n",
    "        \n",
    "        for current_month in timeframe_dict.get(current_timeframe):\n",
    "        \n",
    "            filenames.extend(glob.glob(fr'{raster_dir}GRID_1_Messungen_Tageswerte_2020_TN0_TW_{current_year}{current_month}??_utm.asc'))\n",
    "         \n",
    "        aggregation_results = [raster_mean(filename, polygons) for filename in filenames]\n",
    "        \n",
    "        arr = [np.array(x) for x in zip(*aggregation_results)]\n",
    "        \n",
    "        heatsum_8 = [np.nansum(x[x >= 8.3]) for x in arr]\n",
    "        heatsum_16 = [np.nansum(x[x >= 8.3]) for x in arr]\n",
    "\n",
    "\n",
    "        heatsum_res[0].extend(heatsum_8)         \n",
    "        heatsum_res[1].extend(heatsum_16)   \n",
    "        \n",
    "        merge_dummies = [f'{current_year}-{current_timeframe}-{dist}' for dist in polygons['fdist_id']]\n",
    "        heatsum_res[2].extend(merge_dummies)\n",
    "\n",
    "heatsum_res = pd.DataFrame(heatsum_res).T\n",
    "\n",
    "heatsum_res.columns = ['HS8', 'HS16', 'merge_dummy']\n",
    "\n",
    "print(f'Finished heatsum calculations, total time: {(time.time()-start_time)/60:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['merge_dummy'] = infestation_history['year'].map(lambda x: str(x) + '-') + infestation_history['timeframe'].map(lambda x: x + '-') + infestation_history['fdist_id'].astype(str)\n",
    "\n",
    "infestation_history = pd.merge(\n",
    "    infestation_history, \n",
    "    climate_res, \n",
    "    on='merge_dummy'\n",
    ")\n",
    "\n",
    "infestation_history = pd.merge(\n",
    "    infestation_history, \n",
    "    heatsum_res, \n",
    "    on='merge_dummy'\n",
    ").drop('merge_dummy', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County/District names, ID, timestamp - preparation for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Meißen, logically connect the old forestry districts to the new ones that best approxiamte the location/shape\n",
    "def connect_districts(fdist_name, fdist_id):\n",
    "    if not fdist_id in [2793, 2791]:\n",
    "        return fdist_name\n",
    "    \n",
    "    else:\n",
    "        return fdist_name.replace(\n",
    "            'Nord', 'Ost' # what was M Nord is almost exactly M Ost in the new structure\n",
    "        ).replace(\n",
    "            'West', 'Nord' # M West is best approximated by M Nord in the new structure\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['fdist_newname'] = infestation_history[['fdist_name','fdist_id']].apply(lambda x: connect_districts(x[0], x[1]), axis=1)\n",
    "infestation_history['id'] = infestation_history['county_name'].map(lambda x: x + '-') + infestation_history['fdist_newname'].map(lambda x: x + '-') + infestation_history['forest_ownership']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_timeframe = {\n",
    "    '01 Januar-März': '-03-31',\n",
    "    '04 April': '-04-30',\n",
    "    '05 Mai': '-05-31',\n",
    "    '06 Juni': '-06-30',\n",
    "    '07 Juli': '-07-31',\n",
    "    '08 August': '-08-31',\n",
    "    '09 September': '-09-30',\n",
    "    '10 Oktober-Dezember': '-12-31'\n",
    "    }\n",
    "             \n",
    "     \n",
    "infestation_history['timestamp'] = infestation_history['year'].astype(str) + infestation_history['timeframe'].map(lambda x: end_of_timeframe.get(x))\n",
    "infestation_history['timestamp'] = pd.to_datetime(infestation_history['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounting for previously infested/disposed wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "\n",
    "\n",
    "# for every row map the 'disposed_wood' and 'infested_wood' value of the previous observation with the same 'id'\n",
    "# TODO: documentation\n",
    "\n",
    "prev_disposed_wood = []\n",
    "prev_infested_wood = []\n",
    "prev_infested_wood_ofo = []\n",
    "    \n",
    "for i, row in infestation_history.iterrows():\n",
    "    if row['timestamp'].month in range(4,10):\n",
    "        previous_row = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-1)) & \n",
    "            (infestation_history['id'] == row['id'])\n",
    "        ]\n",
    "        \n",
    "        previous_row_ofo = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-1)) & \n",
    "            (infestation_history['fdist_newname'] == row['fdist_newname']) & \n",
    "            (infestation_history['forest_ownership'] != row['forest_ownership'])\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        previous_row = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-3)) & \n",
    "            (infestation_history['id'] == row['id'])\n",
    "        ]\n",
    "        \n",
    "        previous_row_ofo = infestation_history.loc[\n",
    "            (infestation_history['timestamp'] == row['timestamp'] + MonthEnd(-3)) & \n",
    "            (infestation_history['fdist_newname'] == row['fdist_newname']) & \n",
    "            (infestation_history['forest_ownership'] != row['forest_ownership'])\n",
    "        ]\n",
    "    \n",
    "    pdw = previous_row['disposed_wood'].values\n",
    "    piw = previous_row['infested_wood'].values\n",
    "    piw_ofo = previous_row_ofo['infested_wood'].values\n",
    "    \n",
    "    prev_disposed_wood.append(pdw[0] if len(pdw)==1 else np.nan)\n",
    "    prev_infested_wood.append(piw[0] if len(piw)==1 else np.nan)\n",
    "    prev_infested_wood_ofo.append(piw_ofo[0] if len(piw_ofo==1) else np.nan)\n",
    "    \n",
    "infestation_history['prev_disposed_wood'] = prev_disposed_wood\n",
    "infestation_history['prev_infested_wood'] = prev_infested_wood\n",
    "infestation_history['prev_infested_wood_ofo'] = prev_infested_wood_ofo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages of climate features for the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingyr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollyr' for name in parameter_info], \n",
    "                                   'prev_infested_wood_rollyr',\n",
    "                                   'prev_disposed_wood_rollyr',\n",
    "                                   'HS8_rollyr',\n",
    "                                   'HS16_rollyr'\n",
    "                                  ])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([1 if element.month in range(4, 10) else 3 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollyr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollyr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/12\n",
    "        )\n",
    "    # also do this for prev_infested_wood and prev_disposed_wood\n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'prev_infested_wood_rollyr'\n",
    "    ] = id_subset['prev_infested_wood'].rolling(8).apply(lambda x: np.nansum(x))\n",
    "    \n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'prev_disposed_wood_rollyr'\n",
    "    ] = id_subset['prev_disposed_wood'].rolling(8).apply(lambda x: np.nansum(x))\n",
    "    \n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'HS8_rollyr'\n",
    "    ] = id_subset['HS8'].rolling(8).apply(lambda x: np.nansum(x))\n",
    "    \n",
    "    rolling_df.loc[\n",
    "        rolling_df.index.isin(weighted_parameter.index), \n",
    "        'HS16_rollyr'\n",
    "    ] = id_subset['HS16'].rolling(8).apply(lambda x: np.nansum(x))\n",
    "                          \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingsr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollsr' for name in parameter_info]])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([1 if element.month in range(4, 10) else 0 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollsr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollsr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/6\n",
    "        )\n",
    "                          \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _rollingwr\n",
    "\n",
    "rolling_df = pd.DataFrame(np.nan, \n",
    "                          index=range(infestation_history.shape[0]),\n",
    "                          columns=[*[name + '_rollwr' for name in parameter_info]])\n",
    "\n",
    "for ID in infestation_history['id'].unique(): \n",
    "    \n",
    "    # extract relevant time series for the id, sorted by timestamps\n",
    "    id_subset = infestation_history.loc[infestation_history['id'] == ID].sort_values('timestamp')\n",
    "    \n",
    "    # the timeframes with three months need to be weighted accordingly\n",
    "    weight = pd.Series([0 if element.month in range(4, 10) else 1 for element in id_subset['timestamp']])\n",
    "        \n",
    "    # calculate moving average for every meteorological parameter\n",
    "    for current_parameter in parameter_info:\n",
    "        \n",
    "        # multiply parameter values by weight\n",
    "        # use weight.values to keep the original index from id_subset\n",
    "        weighted_parameter =  pd.Series(id_subset[current_parameter] * weight.values, name=current_parameter+'_rollwr')\n",
    "        \n",
    "        # perform rolling, save results in rolling_df\n",
    "        rolling_df.loc[\n",
    "            rolling_df.index.isin(weighted_parameter.index), \n",
    "            current_parameter+'_rollwr'\n",
    "        ] = weighted_parameter.rolling(8).apply(\n",
    "            lambda x: np.nansum(x)/6\n",
    "        )\n",
    "           \n",
    "# sice we kept the original indeces, merge results on index        \n",
    "infestation_history = pd.merge(infestation_history, rolling_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endangered area for this id\n",
    "infestation_history['area_endangered'] = infestation_history[['forest_ownership', 'area_nse', 'area_se']].apply(lambda x: x[1] if x[0] == 'NSW' else x[2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windfall and demolition wood \n",
    "\n",
    "Abiotic damages - Bruch & Wurf, Schnee,Eis u. Sturm kombiniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data set\n",
    "demolition_history = pd.read_excel(r'data_raw/ML_WB_20201112.xlsx', \n",
    "                                    names=['county_acronym', 'county_nr', 'fdist_nr', 'fdist_id','year', \n",
    "                                           'timeframe', 'forest_ownership', 'demolition_wood', 'disposed_demolition_wood'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just like with infestation_history, we drop the redundant columns\n",
    "demolition_history.drop(['county_acronym', 'county_nr', 'fdist_nr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add *Stadtwald Zittau*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in column 'fdist_id' change all occurrences of 2691 to 2601\n",
    "demolition_history['fdist_id'] = demolition_history['fdist_id'].replace(2691, 2601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before zero_fill(): 1945\n",
      "Number of rows after zero_fill(): 3405\n"
     ]
    }
   ],
   "source": [
    "# use the fruits of our labor to fill zero rows\n",
    "demolition_history = zero_fill(demolition_history)\n",
    "\n",
    "# since there could be manual entry errors etc. get the new name NOW so we can later merge back on that\n",
    "# use the fruits of our labor and merge fdist_ids on fdist_newname to logically connect old and new districts\n",
    "newname_df = infestation_history[['fdist_id', 'fdist_newname']].drop_duplicates('fdist_id').copy()\n",
    "\n",
    "demolition_history = pd.merge(demolition_history, newname_df, on='fdist_id')\n",
    "\n",
    "# aggregate the values by summing them together for the 'demolition_wood' and 'disposed_demolition_wood' columns if every other column value is the same\n",
    "demolition_history['demolition_wood'] = demolition_history.groupby(['fdist_newname', 'year', 'timeframe', 'forest_ownership'])['demolition_wood'].transform('sum')\n",
    "\n",
    "demolition_history['disposed_demolition_wood'] = demolition_history.groupby(['fdist_newname', 'year', 'timeframe', 'forest_ownership'])['disposed_demolition_wood'].transform('sum')\n",
    "\n",
    "# Now drop the duplicated rows that were just created\n",
    "demolition_history.drop_duplicates(['fdist_newname', 'year', 'timeframe', 'forest_ownership'], inplace=True)\n",
    "\n",
    "# reset the index\n",
    "demolition_history.reset_index(inplace=True, drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all other timeframes except April and September with the right values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_demolition_date(timestamp):\n",
    "    '''\n",
    "    TODO: documentation\n",
    "    '''\n",
    "    if timestamp.month in [4, 9]:\n",
    "        return timestamp\n",
    "    elif timestamp.month in range(5, 9):\n",
    "        return date(timestamp.year, 4, 30)\n",
    "    elif timestamp.month in range(1, 4):\n",
    "        return date(timestamp.year - 1, 9, 30)\n",
    "    else:\n",
    "        return date(timestamp.year, 9, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "demolition_history['timestamp'] = demolition_history['year'].astype(str) + demolition_history['timeframe'].map(lambda x: end_of_timeframe.get(x))\n",
    "demolition_history['timestamp'] = pd.to_datetime(demolition_history['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['demolition_date'] = infestation_history['timestamp'].map(lambda x: prev_demolition_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>forest_ownership</th>\n",
       "      <th>demolition_wood</th>\n",
       "      <th>disposed_demolition_wood</th>\n",
       "      <th>fdist_newname</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fdist_id, year, timeframe, forest_ownership, demolition_wood, disposed_demolition_wood, fdist_newname, timestamp]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demolition_history[demolition_history.duplicated(['fdist_newname','forest_ownership', 'timestamp'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history = pd.merge(\n",
    "    infestation_history, \n",
    "    demolition_history[[\n",
    "        'fdist_newname',\n",
    "        'forest_ownership', \n",
    "        'timestamp', \n",
    "        'demolition_wood', \n",
    "        'disposed_demolition_wood']], \n",
    "    left_on=['fdist_newname', 'forest_ownership', 'demolition_date'], \n",
    "    right_on=['fdist_newname', 'forest_ownership', 'timestamp'], \n",
    "    suffixes=('', '_drop'),\n",
    "    how='left'\n",
    ").drop(['demolition_date', 'timestamp_drop'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdist_id</th>\n",
       "      <th>year</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>forest_ownership</th>\n",
       "      <th>infested_wood</th>\n",
       "      <th>disposed_wood</th>\n",
       "      <th>county_name</th>\n",
       "      <th>fdist_name</th>\n",
       "      <th>area_nse</th>\n",
       "      <th>area_nsne</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_sne</th>\n",
       "      <th>centroid_xcoord</th>\n",
       "      <th>centroid_ycoord</th>\n",
       "      <th>area_fdist</th>\n",
       "      <th>endangered_forest_density</th>\n",
       "      <th>TX0</th>\n",
       "      <th>TM0</th>\n",
       "      <th>TN0</th>\n",
       "      <th>RF0</th>\n",
       "      <th>SD0</th>\n",
       "      <th>RRU</th>\n",
       "      <th>RRK</th>\n",
       "      <th>FF1</th>\n",
       "      <th>FF2</th>\n",
       "      <th>FFB</th>\n",
       "      <th>RGK</th>\n",
       "      <th>ETP</th>\n",
       "      <th>GRV</th>\n",
       "      <th>KWU</th>\n",
       "      <th>KWK</th>\n",
       "      <th>HS8</th>\n",
       "      <th>HS16</th>\n",
       "      <th>fdist_newname</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prev_disposed_wood</th>\n",
       "      <th>prev_infested_wood</th>\n",
       "      <th>prev_infested_wood_ofo</th>\n",
       "      <th>TX0_rollyr</th>\n",
       "      <th>TM0_rollyr</th>\n",
       "      <th>TN0_rollyr</th>\n",
       "      <th>RF0_rollyr</th>\n",
       "      <th>SD0_rollyr</th>\n",
       "      <th>RRU_rollyr</th>\n",
       "      <th>RRK_rollyr</th>\n",
       "      <th>FF1_rollyr</th>\n",
       "      <th>FF2_rollyr</th>\n",
       "      <th>FFB_rollyr</th>\n",
       "      <th>RGK_rollyr</th>\n",
       "      <th>ETP_rollyr</th>\n",
       "      <th>GRV_rollyr</th>\n",
       "      <th>KWU_rollyr</th>\n",
       "      <th>KWK_rollyr</th>\n",
       "      <th>prev_infested_wood_rollyr</th>\n",
       "      <th>prev_disposed_wood_rollyr</th>\n",
       "      <th>HS8_rollyr</th>\n",
       "      <th>HS16_rollyr</th>\n",
       "      <th>TX0_rollsr</th>\n",
       "      <th>TM0_rollsr</th>\n",
       "      <th>TN0_rollsr</th>\n",
       "      <th>RF0_rollsr</th>\n",
       "      <th>SD0_rollsr</th>\n",
       "      <th>RRU_rollsr</th>\n",
       "      <th>RRK_rollsr</th>\n",
       "      <th>FF1_rollsr</th>\n",
       "      <th>FF2_rollsr</th>\n",
       "      <th>FFB_rollsr</th>\n",
       "      <th>RGK_rollsr</th>\n",
       "      <th>ETP_rollsr</th>\n",
       "      <th>GRV_rollsr</th>\n",
       "      <th>KWU_rollsr</th>\n",
       "      <th>KWK_rollsr</th>\n",
       "      <th>TX0_rollwr</th>\n",
       "      <th>TM0_rollwr</th>\n",
       "      <th>TN0_rollwr</th>\n",
       "      <th>RF0_rollwr</th>\n",
       "      <th>SD0_rollwr</th>\n",
       "      <th>RRU_rollwr</th>\n",
       "      <th>RRK_rollwr</th>\n",
       "      <th>FF1_rollwr</th>\n",
       "      <th>FF2_rollwr</th>\n",
       "      <th>FFB_rollwr</th>\n",
       "      <th>RGK_rollwr</th>\n",
       "      <th>ETP_rollwr</th>\n",
       "      <th>GRV_rollwr</th>\n",
       "      <th>KWU_rollwr</th>\n",
       "      <th>KWK_rollwr</th>\n",
       "      <th>area_endangered</th>\n",
       "      <th>demolition_wood</th>\n",
       "      <th>disposed_demolition_wood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8410</th>\n",
       "      <td>2704</td>\n",
       "      <td>2013</td>\n",
       "      <td>08 August</td>\n",
       "      <td>SW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>384941.58554</td>\n",
       "      <td>5.684987e+06</td>\n",
       "      <td>378.29004</td>\n",
       "      <td>9.558803</td>\n",
       "      <td>25.5675</td>\n",
       "      <td>18.8919</td>\n",
       "      <td>12.5429</td>\n",
       "      <td>69.7946</td>\n",
       "      <td>228.568</td>\n",
       "      <td>37.0475</td>\n",
       "      <td>41.0908</td>\n",
       "      <td>2.67386</td>\n",
       "      <td>1.94619</td>\n",
       "      <td>2.13399</td>\n",
       "      <td>136.811</td>\n",
       "      <td>101.182</td>\n",
       "      <td>99.5412</td>\n",
       "      <td>-64.1349</td>\n",
       "      <td>-60.0915</td>\n",
       "      <td>374.969</td>\n",
       "      <td>374.969</td>\n",
       "      <td>M West</td>\n",
       "      <td>Meißen-M West-SW</td>\n",
       "      <td>2013-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8411</th>\n",
       "      <td>2704</td>\n",
       "      <td>2013</td>\n",
       "      <td>08 August</td>\n",
       "      <td>NSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>384941.58554</td>\n",
       "      <td>5.684987e+06</td>\n",
       "      <td>378.29004</td>\n",
       "      <td>9.558803</td>\n",
       "      <td>25.5675</td>\n",
       "      <td>18.8919</td>\n",
       "      <td>12.5429</td>\n",
       "      <td>69.7946</td>\n",
       "      <td>228.568</td>\n",
       "      <td>37.0475</td>\n",
       "      <td>41.0908</td>\n",
       "      <td>2.67386</td>\n",
       "      <td>1.94619</td>\n",
       "      <td>2.13399</td>\n",
       "      <td>136.811</td>\n",
       "      <td>101.182</td>\n",
       "      <td>99.5412</td>\n",
       "      <td>-64.1349</td>\n",
       "      <td>-60.0915</td>\n",
       "      <td>374.969</td>\n",
       "      <td>374.969</td>\n",
       "      <td>M West</td>\n",
       "      <td>Meißen-M West-NSW</td>\n",
       "      <td>2013-08-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>2704</td>\n",
       "      <td>2013</td>\n",
       "      <td>07 Juli</td>\n",
       "      <td>SW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>384941.58554</td>\n",
       "      <td>5.684987e+06</td>\n",
       "      <td>378.29004</td>\n",
       "      <td>9.558803</td>\n",
       "      <td>26.6843</td>\n",
       "      <td>20.2111</td>\n",
       "      <td>13.5906</td>\n",
       "      <td>69.032</td>\n",
       "      <td>305.959</td>\n",
       "      <td>34.9166</td>\n",
       "      <td>37.6292</td>\n",
       "      <td>2.57407</td>\n",
       "      <td>1.88758</td>\n",
       "      <td>2.05033</td>\n",
       "      <td>180.731</td>\n",
       "      <td>133.936</td>\n",
       "      <td>131.126</td>\n",
       "      <td>-99.0196</td>\n",
       "      <td>-96.307</td>\n",
       "      <td>423.479</td>\n",
       "      <td>423.479</td>\n",
       "      <td>M West</td>\n",
       "      <td>Meißen-M West-SW</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>2704</td>\n",
       "      <td>2013</td>\n",
       "      <td>07 Juli</td>\n",
       "      <td>NSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Meißen</td>\n",
       "      <td>M West</td>\n",
       "      <td>36.08</td>\n",
       "      <td>1499.801018</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3411.198775</td>\n",
       "      <td>384941.58554</td>\n",
       "      <td>5.684987e+06</td>\n",
       "      <td>378.29004</td>\n",
       "      <td>9.558803</td>\n",
       "      <td>26.6843</td>\n",
       "      <td>20.2111</td>\n",
       "      <td>13.5906</td>\n",
       "      <td>69.032</td>\n",
       "      <td>305.959</td>\n",
       "      <td>34.9166</td>\n",
       "      <td>37.6292</td>\n",
       "      <td>2.57407</td>\n",
       "      <td>1.88758</td>\n",
       "      <td>2.05033</td>\n",
       "      <td>180.731</td>\n",
       "      <td>133.936</td>\n",
       "      <td>131.126</td>\n",
       "      <td>-99.0196</td>\n",
       "      <td>-96.307</td>\n",
       "      <td>423.479</td>\n",
       "      <td>423.479</td>\n",
       "      <td>M West</td>\n",
       "      <td>Meißen-M West-NSW</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fdist_id  year  timeframe forest_ownership  infested_wood  \\\n",
       "8410      2704  2013  08 August               SW            0.0   \n",
       "8411      2704  2013  08 August              NSW            0.0   \n",
       "8476      2704  2013    07 Juli               SW            0.0   \n",
       "8477      2704  2013    07 Juli              NSW            0.0   \n",
       "\n",
       "      disposed_wood county_name fdist_name  area_nse    area_nsne  area_se  \\\n",
       "8410            0.0      Meißen     M West     36.08  1499.801018     0.08   \n",
       "8411            0.0      Meißen     M West     36.08  1499.801018     0.08   \n",
       "8476            0.0      Meißen     M West     36.08  1499.801018     0.08   \n",
       "8477            0.0      Meißen     M West     36.08  1499.801018     0.08   \n",
       "\n",
       "         area_sne  centroid_xcoord  centroid_ycoord  area_fdist  \\\n",
       "8410  3411.198775     384941.58554     5.684987e+06   378.29004   \n",
       "8411  3411.198775     384941.58554     5.684987e+06   378.29004   \n",
       "8476  3411.198775     384941.58554     5.684987e+06   378.29004   \n",
       "8477  3411.198775     384941.58554     5.684987e+06   378.29004   \n",
       "\n",
       "      endangered_forest_density      TX0      TM0      TN0      RF0      SD0  \\\n",
       "8410                   9.558803  25.5675  18.8919  12.5429  69.7946  228.568   \n",
       "8411                   9.558803  25.5675  18.8919  12.5429  69.7946  228.568   \n",
       "8476                   9.558803  26.6843  20.2111  13.5906   69.032  305.959   \n",
       "8477                   9.558803  26.6843  20.2111  13.5906   69.032  305.959   \n",
       "\n",
       "          RRU      RRK      FF1      FF2      FFB      RGK      ETP      GRV  \\\n",
       "8410  37.0475  41.0908  2.67386  1.94619  2.13399  136.811  101.182  99.5412   \n",
       "8411  37.0475  41.0908  2.67386  1.94619  2.13399  136.811  101.182  99.5412   \n",
       "8476  34.9166  37.6292  2.57407  1.88758  2.05033  180.731  133.936  131.126   \n",
       "8477  34.9166  37.6292  2.57407  1.88758  2.05033  180.731  133.936  131.126   \n",
       "\n",
       "          KWU      KWK      HS8     HS16 fdist_newname                 id  \\\n",
       "8410 -64.1349 -60.0915  374.969  374.969        M West   Meißen-M West-SW   \n",
       "8411 -64.1349 -60.0915  374.969  374.969        M West  Meißen-M West-NSW   \n",
       "8476 -99.0196  -96.307  423.479  423.479        M West   Meißen-M West-SW   \n",
       "8477 -99.0196  -96.307  423.479  423.479        M West  Meißen-M West-NSW   \n",
       "\n",
       "      timestamp  prev_disposed_wood  prev_infested_wood  \\\n",
       "8410 2013-08-31                 0.0                 0.0   \n",
       "8411 2013-08-31                 0.0                 0.0   \n",
       "8476 2013-07-31                 NaN                 NaN   \n",
       "8477 2013-07-31                 NaN                 NaN   \n",
       "\n",
       "      prev_infested_wood_ofo  TX0_rollyr  TM0_rollyr  TN0_rollyr  RF0_rollyr  \\\n",
       "8410                     0.0         NaN         NaN         NaN         NaN   \n",
       "8411                     0.0         NaN         NaN         NaN         NaN   \n",
       "8476                     NaN         NaN         NaN         NaN         NaN   \n",
       "8477                     NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      SD0_rollyr  RRU_rollyr  RRK_rollyr  FF1_rollyr  FF2_rollyr  FFB_rollyr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      RGK_rollyr  ETP_rollyr  GRV_rollyr  KWU_rollyr  KWK_rollyr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      prev_infested_wood_rollyr  prev_disposed_wood_rollyr  HS8_rollyr  \\\n",
       "8410                        NaN                        NaN         NaN   \n",
       "8411                        NaN                        NaN         NaN   \n",
       "8476                        NaN                        NaN         NaN   \n",
       "8477                        NaN                        NaN         NaN   \n",
       "\n",
       "      HS16_rollyr  TX0_rollsr  TM0_rollsr  TN0_rollsr  RF0_rollsr  SD0_rollsr  \\\n",
       "8410          NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411          NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476          NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477          NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      RRU_rollsr  RRK_rollsr  FF1_rollsr  FF2_rollsr  FFB_rollsr  RGK_rollsr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      ETP_rollsr  GRV_rollsr  KWU_rollsr  KWK_rollsr  TX0_rollwr  TM0_rollwr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      TN0_rollwr  RF0_rollwr  SD0_rollwr  RRU_rollwr  RRK_rollwr  FF1_rollwr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      FF2_rollwr  FFB_rollwr  RGK_rollwr  ETP_rollwr  GRV_rollwr  KWU_rollwr  \\\n",
       "8410         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8411         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8476         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "8477         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "      KWK_rollwr  area_endangered  demolition_wood  disposed_demolition_wood  \n",
       "8410         NaN             0.08              NaN                       NaN  \n",
       "8411         NaN            36.08              NaN                       NaN  \n",
       "8476         NaN             0.08              NaN                       NaN  \n",
       "8477         NaN            36.08              NaN                       NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infestation_history[(infestation_history['demolition_wood'].isna()) & (infestation_history['year'] > 2005)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history[['demolition_wood', 'disposed_demolition_wood']] = infestation_history[['demolition_wood', 'disposed_demolition_wood']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history['disposing_rate_demolition'] = infestation_history[['demolition_wood', 'disposed_demolition_wood']].apply(lambda x: 1 if x[0]==0 else x[1]/x[0], axis=1)  \n",
    "infestation_history['disposing_rate_infested_yr'] = infestation_history[['prev_infested_wood_rollyr', 'prev_disposed_wood_rollyr']].apply(lambda x: 1 if x[0]==0 else x[1]/x[0], axis=1)  \n",
    "\n",
    "# rounding or entry errors or if more was disposed: still 1\n",
    "infestation_history['disposing_rate_demolition'] = infestation_history['disposing_rate_demolition'].map(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "infestation_history['disposing_rate_infested_yr'] = infestation_history['disposing_rate_infested_yr'].map(lambda x: 1 if x > 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13484 entries, 0 to 13483\n",
      "Data columns (total 93 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   fdist_id                    13484 non-null  int64         \n",
      " 1   year                        13484 non-null  int64         \n",
      " 2   timeframe                   13484 non-null  object        \n",
      " 3   forest_ownership            13484 non-null  object        \n",
      " 4   infested_wood               13484 non-null  float64       \n",
      " 5   disposed_wood               13484 non-null  float64       \n",
      " 6   county_name                 13484 non-null  object        \n",
      " 7   fdist_name                  13484 non-null  object        \n",
      " 8   area_nse                    13484 non-null  float64       \n",
      " 9   area_nsne                   13484 non-null  float64       \n",
      " 10  area_se                     13484 non-null  float64       \n",
      " 11  area_sne                    13484 non-null  float64       \n",
      " 12  centroid_xcoord             13484 non-null  float64       \n",
      " 13  centroid_ycoord             13484 non-null  float64       \n",
      " 14  area_fdist                  13484 non-null  float64       \n",
      " 15  endangered_forest_density   13484 non-null  float64       \n",
      " 16  TX0                         12848 non-null  object        \n",
      " 17  TM0                         12848 non-null  object        \n",
      " 18  TN0                         12848 non-null  object        \n",
      " 19  RF0                         12848 non-null  object        \n",
      " 20  SD0                         12848 non-null  object        \n",
      " 21  RRU                         12848 non-null  object        \n",
      " 22  RRK                         12848 non-null  object        \n",
      " 23  FF1                         12848 non-null  object        \n",
      " 24  FF2                         12848 non-null  object        \n",
      " 25  FFB                         12848 non-null  object        \n",
      " 26  RGK                         12848 non-null  object        \n",
      " 27  ETP                         12848 non-null  object        \n",
      " 28  GRV                         12848 non-null  object        \n",
      " 29  KWU                         12848 non-null  object        \n",
      " 30  KWK                         12848 non-null  object        \n",
      " 31  HS8                         12848 non-null  object        \n",
      " 32  HS16                        12848 non-null  object        \n",
      " 33  fdist_newname               13484 non-null  object        \n",
      " 34  id                          13484 non-null  object        \n",
      " 35  timestamp                   13484 non-null  datetime64[ns]\n",
      " 36  prev_disposed_wood          13376 non-null  float64       \n",
      " 37  prev_infested_wood          13376 non-null  float64       \n",
      " 38  prev_infested_wood_ofo      13376 non-null  float64       \n",
      " 39  TX0_rollyr                  12092 non-null  float64       \n",
      " 40  TM0_rollyr                  12092 non-null  float64       \n",
      " 41  TN0_rollyr                  12092 non-null  float64       \n",
      " 42  RF0_rollyr                  12092 non-null  float64       \n",
      " 43  SD0_rollyr                  12092 non-null  float64       \n",
      " 44  RRU_rollyr                  12092 non-null  float64       \n",
      " 45  RRK_rollyr                  12092 non-null  float64       \n",
      " 46  FF1_rollyr                  12092 non-null  float64       \n",
      " 47  FF2_rollyr                  12092 non-null  float64       \n",
      " 48  FFB_rollyr                  12092 non-null  float64       \n",
      " 49  RGK_rollyr                  12092 non-null  float64       \n",
      " 50  ETP_rollyr                  12092 non-null  float64       \n",
      " 51  GRV_rollyr                  12092 non-null  float64       \n",
      " 52  KWU_rollyr                  12092 non-null  float64       \n",
      " 53  KWK_rollyr                  12092 non-null  float64       \n",
      " 54  prev_infested_wood_rollyr   12620 non-null  float64       \n",
      " 55  prev_disposed_wood_rollyr   0 non-null      float64       \n",
      " 56  HS8_rollyr                  12092 non-null  float64       \n",
      " 57  HS16_rollyr                 12092 non-null  float64       \n",
      " 58  TX0_rollsr                  12092 non-null  float64       \n",
      " 59  TM0_rollsr                  12092 non-null  float64       \n",
      " 60  TN0_rollsr                  12092 non-null  float64       \n",
      " 61  RF0_rollsr                  12092 non-null  float64       \n",
      " 62  SD0_rollsr                  12092 non-null  float64       \n",
      " 63  RRU_rollsr                  12092 non-null  float64       \n",
      " 64  RRK_rollsr                  12092 non-null  float64       \n",
      " 65  FF1_rollsr                  12092 non-null  float64       \n",
      " 66  FF2_rollsr                  12092 non-null  float64       \n",
      " 67  FFB_rollsr                  12092 non-null  float64       \n",
      " 68  RGK_rollsr                  12092 non-null  float64       \n",
      " 69  ETP_rollsr                  12092 non-null  float64       \n",
      " 70  GRV_rollsr                  12092 non-null  float64       \n",
      " 71  KWU_rollsr                  12092 non-null  float64       \n",
      " 72  KWK_rollsr                  12092 non-null  float64       \n",
      " 73  TX0_rollwr                  12092 non-null  float64       \n",
      " 74  TM0_rollwr                  12092 non-null  float64       \n",
      " 75  TN0_rollwr                  12092 non-null  float64       \n",
      " 76  RF0_rollwr                  12092 non-null  float64       \n",
      " 77  SD0_rollwr                  12092 non-null  float64       \n",
      " 78  RRU_rollwr                  12092 non-null  float64       \n",
      " 79  RRK_rollwr                  12092 non-null  float64       \n",
      " 80  FF1_rollwr                  12092 non-null  float64       \n",
      " 81  FF2_rollwr                  12092 non-null  float64       \n",
      " 82  FFB_rollwr                  12092 non-null  float64       \n",
      " 83  RGK_rollwr                  12092 non-null  float64       \n",
      " 84  ETP_rollwr                  12092 non-null  float64       \n",
      " 85  GRV_rollwr                  12092 non-null  float64       \n",
      " 86  KWU_rollwr                  12092 non-null  float64       \n",
      " 87  KWK_rollwr                  12092 non-null  float64       \n",
      " 88  area_endangered             13484 non-null  float64       \n",
      " 89  demolition_wood             13484 non-null  float64       \n",
      " 90  disposed_demolition_wood    13484 non-null  float64       \n",
      " 91  disposing_rate_demolition   13484 non-null  float64       \n",
      " 92  disposing_rate_infested_yr  3216 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(67), int64(2), object(23)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "infestation_history.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "infestation_history.to_csv('barkbeetle_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
